{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = '/Users/leahbriscoe/Documents/MicroBatch/microbatch_vc/data/'\n",
    "plot_folder = '/Users/leahbriscoe/Documents/MicroBatch/microbatch_vc/plots/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_names =[ 'kmer_BatchCorrected_bmi_corrected_pearson_and_mse',\n",
    "#              'kmer_BatchCorrected_bmi_corrected_pearson_and_mse',\n",
    "#              'kmer_BatchCorrected_bmi_corrected_pearson_and_mse',\n",
    "#              'kmer_BatchCorrected_bmi_corrected_pearson_and_mse']\n",
    "             #'kmer_BatchCorrected_bmi_corrected_pearson_and_mse']\n",
    "\n",
    "    #'otu_BatchCorrected_bmi_corrected_pearson_and_mse'\n",
    "#'kmer_kmer_table_bmi_corrected_pearson_and_mse',\n",
    "\n",
    "#['bmi_corrected_pearson_and_mse','bmi_corrected_pearson_and_mse']\n",
    "# folder_names = ['AGP_Hfilter_otu','AGP_Hfilter_k6/robust_k','AGP_Hfilter_k7/robust_k']\n",
    "# file_names =[ 'otu_BatchCorrected_antibiotic_classification_auc',\n",
    "#              'kmer_BatchCorrected_antibiotic_classification_auc',\n",
    "#              'kmer_BatchCorrected_antibiotic_classification_auc']\n",
    "\n",
    "# nice_names = [\"OTU\",\"KMER\",\"KMER\"]\n",
    "\n",
    "#select_labels =[\"Raw\",\"Phen Correct\"]#[\"raw\",\"BMC\",\"ComBat\",\"limma\",\"SmartSVA (n. PCs =7)\",\"MINERVA (n. PCs =6)\"]#[0,1,2,3,4,5,6,7,8,9,10]#[\"raw\",\"BMC\",\"ComBat\",\"limma\",\"SmartSVA (n. PCs =5)\",\"MINERVA (n. PCs =5)\"]#[0,1,2,3,4,5,6,7,8,9,10]#\n",
    "#[\"raw\",\"MINERVA+ (n. PCs =8)\", \"MINERVA+ (n. PCs =9)\",\"MINERVA+ (n. PCs =10)\",\"MINERVA (n. PCs =8)\",\"MINERVA (n. PCs =9)\",\"MINERVA (n. PCs =10)\"]# [\"raw\",\"ComBat\",\"limma\",\"SmartSVA (n. PCs =10)\",\"MINERVA (n. PCs =10)\"]##[0.20,0.40,0.60,0.80]#[\"raw\",\"ComBat\",\"BMC\",\"limma\",\"SmartSVA (n. PCs =1)\",\"MINERVA (n. PCs =1)\"]# [\"5-mer\",\"6-mer\",\"7-mer\"]#\n",
    "alternate_color = False\n",
    "simple_minerva_label = True\n",
    "\n",
    "\n",
    "key =\"MINERVA_grid\"\n",
    "subfile = \"\"\n",
    "select_columns_bool = False\n",
    "shortened_shortened = False\n",
    "trans_vec = False\n",
    "add_linmodel_type = False\n",
    "\n",
    "if key == \"MINERVA_grid\":\n",
    "    numPc = [0,0,0,0,0] \n",
    "    phen = [\"bin_crc_normal\"  for i in range(len(numPc))]#\" #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"colorectal cancer status\" #\"antibiotic history\" #\"colorectal cancer status\"#\"bmi\"#\"bmi\"#\"antibiotic history\" #\"colorectal cancer status\"#\"Preterm Birth\"#\"\n",
    "    phen_type = \"class\"\n",
    "    \n",
    "    \n",
    "    folder_names = [\"CRC_k7\" for i in range(len(numPc))]\n",
    "    \n",
    "    file_names = ['raw_grid','ComBat_grid','limma_grid','MINERVA_grid','MINERVA_grid']   #['smartsva_first10' + str(numPc[i]) + 'filter_TRUE' for i in range(len(numPc))],\n",
    "    select_columns_bool = True\n",
    "    \n",
    "    if simple_minerva_label:\n",
    "        select_labels = [\"raw\",\"ComBat\",\"limma\",\"MINERVA\",\"MINERVA\"] #\"Refactor (n. PCs =9)\",\"SmartSVA (n. PCs =3)\",\n",
    "   \n",
    "    else:\n",
    "        select_labels = [\"raw\",\"ComBat\",\"limma\",\"MINERVA (n. PCs =1)\",\"MINERVA (n. PCs =1)\"]#[0,1,2,3,4,5,6,7,8,9,10]#[\"raw\",\"BMC\",\"ComBat\",\"limma\",\"SmartSVA (n. PCs =5)\",\"MINERVA (n. PCs =5)\"]#[0,1,2,3,4,5,6,7,8,9,10]#\n",
    "    \n",
    "   \n",
    "    metric_word = \"auc_all\"\n",
    "    chosen_classifier = \"Random Forest\"\n",
    "    title = 'AUC for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "    pair_test_all = True\n",
    "    limit_spec =(0.4,1)\n",
    "    shortened=True\n",
    "    not_rotate=False\n",
    "    trans_vec = True\n",
    "    trans = [\"none\",\"none\",\"none\",\"none\",\"clr_scale\"]\n",
    "\n",
    "    \n",
    "if key == \"Hispanic_BMI\":\n",
    "    numPc = [0,0,0,0,2]#,11,12,13,14,15,16,17,18,19,20] \n",
    "    phen = [\"bmi_v2\" for i in range(len(numPc))]#\" #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"body mass index (BMI)\" #\"antibiotic history\" #\"colorectal cancer status\"#\"bmi\"#\"bmi\"#\"antibiotic history\" #\"colorectal cancer status\"#\"Preterm Birth\"#\"\n",
    "    phen_type = \"cont\" \n",
    "    \n",
    "    folder_names = [\"Hispanic_k6\" for i in range(len(numPc))]\n",
    "    file_names = ['rawfilter_TRUE','bmcfilter_TRUE','ComBatfilter_TRUE','limmafilter_TRUE','minerva_first2filter_TRUE'] \n",
    "    select_columns_bool = True\n",
    "    select_labels = [\"Raw\",\"BMC\",\"ComBat\",\"limma\",\"MINERVA (n. PCs =2)\"] #\"Refactor (n. PCs =9)\",\"SmartSVA (n. PCs =3)\",\n",
    "    metric_word = \"pearson\"\n",
    "    chosen_classifier = \"Naive Bayes\"\n",
    "    title = 'Pearson for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "    pair_test_all = True\n",
    "    trans = \"clr_scale\"\n",
    "    limit_spec =(-0.1,0.25)\n",
    "    shortened=True\n",
    "    not_rotate=False\n",
    "    \n",
    "    subfile = \"\"\n",
    "\n",
    "\n",
    "if key == \"Hispanic_BMI_calibrate\":\n",
    "    numPc = [0,1,2,3,4,5,6,7,8,9,10,11]#,11,12,13,14,15,16,17,18,19,20] \n",
    "    phen = [\"bmi_v2\" for i in range(len(numPc))]#\" #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"body mass index (BMI)\" #\"antibiotic history\" #\"colorectal cancer status\"#\"bmi\"#\"bmi\"#\"antibiotic history\" #\"colorectal cancer status\"#\"Preterm Birth\"#\"\n",
    "    phen_type = \"cont\" \n",
    "    \n",
    "    folder_names = [\"Hispanic_k7\" for i in range(len(numPc))]\n",
    "    file_names =['rawfilter_TRUE']+['minerva_first' + str(numPc[i]) + 'filter_TRUE' for i in range(1,len(numPc))]\n",
    "    select_columns_bool = True\n",
    "    select_labels = numPc#[\"Raw\"] + [\"MINERVA\" + str(i) for i in range(1,len(numPc))] \n",
    "    metric_word = \"pearson\"\n",
    "    chosen_classifier = \"Naive Bayes\"\n",
    "    title = 'Pearson for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "    pair_test_all = False\n",
    "    trans = \"clr_scale\"\n",
    "    limit_spec =(-0.1,0.25)\n",
    "    shortened=True\n",
    "    not_rotate=True\n",
    "    add_linmodel_type  = True\n",
    "    \n",
    "    subfile = \"\"\n",
    "    \n",
    "if key == \"Hispanic_abx\":\n",
    "    numPc = [0,0,0,0,11]#,11,12,13,14,15,16,17,18,19,20] \n",
    "    phen = [\"antibiotic\" for i in range(len(numPc))]#\" #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"antibiotic history\" \n",
    "    phen_type = \"class\" \n",
    "    \n",
    "    folder_names = [\"Hispanic_k7\" for i in range(len(numPc))]\n",
    "    file_names = ['rawfilter_TRUE','bmcfilter_TRUE','ComBatfilter_TRUE','limmafilter_TRUE','minerva_first11filter_TRUE'] \n",
    "    select_columns_bool = True\n",
    "    if simple_minerva_label:\n",
    "        select_labels = [\"Raw\",\"BMC\",\"ComBat\",\"limma\",\"MINERVA\"] #\"Refactor (n. PCs =9)\",\"SmartSVA (n. PCs =3)\",\n",
    "   \n",
    "    else:\n",
    "        select_labels = [\"Raw\",\"BMC\",\"ComBat\",\"limma\",\"MINERVA (n. PCs =11)\"] #\"Refactor (n. PCs =9)\",\"SmartSVA (n. PCs =3)\",\n",
    "    metric_word = \"auc_all\"\n",
    "    chosen_classifier = \"Naive Bayes\"\n",
    "    title = 'AUC for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "    pair_test_all = True\n",
    "    trans = \"clr_scale\"\n",
    "    limit_spec =(0.45,0.8)\n",
    "    shortened=True\n",
    "    not_rotate=False\n",
    "    subfile = \"\"\n",
    "if key == \"Hispanic_abx_calibrate\":\n",
    "    numPc = [0,1,2,3,4,5,6,7,8,9,10,11,12,14] \n",
    "    phen = [\"antibiotic\" for i in range(len(numPc))]#\" #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"antibiotic history\" \n",
    "    phen_type = \"class\" \n",
    "    \n",
    "    folder_names = [\"Hispanic_k7\" for i in range(len(numPc))]\n",
    "    file_names =['rawfilter_TRUE']+['minerva_first' + str(numPc[i]) + 'filter_TRUE' for i in range(1,len(numPc))]\n",
    "    select_columns_bool = True\n",
    "    #select_labels = [\"Raw\"] + [\"MINERVA\" + str(i) for i in range(1,len(numPc))] \n",
    "    select_labels = numPc\n",
    "    metric_word = \"auc_all\"\n",
    "    chosen_classifier = \"Naive Bayes\"\n",
    "    title = 'AUC for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "    pair_test_all = False\n",
    "    trans = \"clr_scale\"  \n",
    "    limit_spec =(0.45,0.80)\n",
    "    not_rotate=True\n",
    "    subfile = \"\"\n",
    "    \n",
    "if key == \"Wirbel_PhenoCorrect\":\n",
    "    phen = [\"DiseaseState\",\"DiseaseState\"]#\" #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"colorectal cancer status\" #\"antibiotic history\" #\"colorectal cancer status\"#\"bmi\"#\"bmi\"#\"antibiotic history\" #\"colorectal cancer status\"#\"Preterm Birth\"#\"\n",
    "    phen_type = \"class\"\n",
    "    metric_word = 'accuracy'\n",
    "    \n",
    "    numPc = [0,0] \n",
    "    folder_names = [\"CRC_wirbel_otu\",\"CRC_wirbel_otu_PhenoCorrect\"]\n",
    "    file_names = ['rawfilter_TRUE','PhenoCorrectfilter_TRUE']\n",
    "    select_columns_bool = True\n",
    "    select_labels = [\"Raw\",\"PhenoCorrect\"]#[0,1,2,3,4,5,6,7,8,9,10]#[\"raw\",\"BMC\",\"ComBat\",\"limma\",\"SmartSVA (n. PCs =5)\",\"MINERVA (n. PCs =5)\"]#[0,1,2,3,4,5,6,7,8,9,10]#\n",
    "    title = 'AUC for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "\n",
    "    chosen_classifier = \"Random Forest\"\n",
    "    title = 'Accuracy for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "    pair_test_all = False\n",
    "    trans = \"clr_scale\"\n",
    "    \n",
    "if key == \"Wirbel_DataAugmentation\":\n",
    "    phen = [\"DiseaseState\",\"DiseaseState\"]#\" #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"colorectal cancer status\" #\"antibiotic history\" #\"colorectal cancer status\"#\"bmi\"#\"bmi\"#\"antibiotic history\" #\"colorectal cancer status\"#\"Preterm Birth\"#\"\n",
    "    phen_type = \"class\"\n",
    "    metric_word = 'accuracy'\n",
    "    \n",
    "    numPc = [0,0] \n",
    "    folder_names = [\"CRC_wirbel_otu\",\"CRC_wirbel_otu_DataAugmentation\"]\n",
    "    file_names = ['rawfilter_TRUE','DataAugmentationfilter_TRUE']\n",
    "    select_columns_bool = True\n",
    "    select_labels = [\"Raw\",\"DataAugmentation\"]#[0,1,2,3,4,5,6,7,8,9,10]#[\"raw\",\"BMC\",\"ComBat\",\"limma\",\"SmartSVA (n. PCs =5)\",\"MINERVA (n. PCs =5)\"]#[0,1,2,3,4,5,6,7,8,9,10]#\n",
    "    title = 'AUC for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "\n",
    "    chosen_classifier = \"Random Forest\"\n",
    "    title = 'Accuracy for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "    pair_test_all = False\n",
    "    trans = \"clr_scale\"\n",
    "\n",
    "if key == \"Thomas_kmer_PredDomainPheno\":\n",
    "    \n",
    "    phen = [\"bin_crc_adenomaORnormal\",\"domain_pheno\"]#\" #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"colorectal cancer status\" #\"antibiotic history\" #\"colorectal cancer status\"#\"bmi\"#\"bmi\"#\"antibiotic history\" #\"colorectal cancer status\"#\"Preterm Birth\"#\"\n",
    "    phen_type = \"class\"\n",
    "    \n",
    "    numPc = [0,0] \n",
    "    folder_names = [\"Thomas_k6\",\"Thomas_k6_PredDomainPheno\"]\n",
    "    file_names = ['rawfilter_TRUE','PredDomainPhenofilter_TRUE']\n",
    "    select_columns_bool = True\n",
    "    select_labels = [\"Raw\",\"PredDomainPheno\"]#[0,1,2,3,4,5,6,7,8,9,10]#[\"raw\",\"BMC\",\"ComBat\",\"limma\",\"SmartSVA (n. PCs =5)\",\"MINERVA (n. PCs =5)\"]#[0,1,2,3,4,5,6,7,8,9,10]#\n",
    "    metric_word = \"accuracy\"\n",
    "    chosen_classifier = \"Random Forest\"\n",
    "    title = 'Accuracy for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "    pair_test_all = False\n",
    "    trans = \"clr_scale\"\n",
    "    \n",
    "if key == \"Thomas_kmer_PhenoCorrect_multi\":\n",
    "    phen = [\"bin_crc_adenomaORnormal\",\"bin_crc_adenomaORnormal\"]#\" #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"colorectal cancer status\" #\"antibiotic history\" #\"colorectal cancer status\"#\"bmi\"#\"bmi\"#\"antibiotic history\" #\"colorectal cancer status\"#\"Preterm Birth\"#\"\n",
    "    phen_type = \"class\"\n",
    "    \n",
    "    numPc = [0,0] \n",
    "    folder_names = [\"Thomas_k6\",\"Thomas_k6_PhenoCorrect\"]\n",
    "    file_names = ['rawfilter_TRUE','PhenoCorrectfilter_TRUE']\n",
    "    select_columns_bool = True\n",
    "    select_labels = [\"Raw\",\"PhenoCorrect\"]#[0,1,2,3,4,5,6,7,8,9,10]#[\"raw\",\"BMC\",\"ComBat\",\"limma\",\"SmartSVA (n. PCs =5)\",\"MINERVA (n. PCs =5)\"]#[0,1,2,3,4,5,6,7,8,9,10]#\n",
    "    metric_word = \"accuracy\"\n",
    "    chosen_classifier = \"Naive Bayes\"\n",
    "    title = 'Accuracy for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "    pair_test_all = False\n",
    "    trans = \"clr_scale\"\n",
    "\n",
    "if key == \"Thomas_kmer_DataAugment\":\n",
    "    phen = [\"bin_crc_adenomaORnormal\",\"bin_crc_adenomaORnormal\"]#\" #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"colorectal cancer status\" #\"antibiotic history\" #\"colorectal cancer status\"#\"bmi\"#\"bmi\"#\"antibiotic history\" #\"colorectal cancer status\"#\"Preterm Birth\"#\"\n",
    "    phen_type = \"class\"\n",
    "    \n",
    "    numPc = [0,0] \n",
    "    folder_names = [\"Thomas_k6\",\"Thomas_k6_DataAugmentation\"]\n",
    "    file_names = ['rawfilter_TRUE','DataAugmentationfilter_TRUE']\n",
    "    select_columns_bool = True\n",
    "    select_labels = [\"Raw\",\"DataAugmentation\"]#[0,1,2,3,4,5,6,7,8,9,10]#[\"raw\",\"BMC\",\"ComBat\",\"limma\",\"SmartSVA (n. PCs =5)\",\"MINERVA (n. PCs =5)\"]#[0,1,2,3,4,5,6,7,8,9,10]#\n",
    "    metric_word = \"accuracy\"\n",
    "    chosen_classifier = \"Random Forest\"\n",
    "    title = 'Accuracy for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "    pair_test_all = False\n",
    "    trans = \"clr_scale\"\n",
    "    \n",
    "if key == \"AGP_abx_time_lapse\":\n",
    "    kmer_spec = 7\n",
    "    numPc = [0,0] \n",
    "    phen = [\"Abx0_6\",\"Abx6_12\"]#\" #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"antibiotic history at 0-6 mo, 6-12 mo\"\n",
    "    phen_type = \"class\" \n",
    "    \n",
    "    folder_names = [\"AGP_max_k\" + str(kmer_spec) + \"_Abx0_6\",\"AGP_max_k\" + str(kmer_spec) + \"_Abx6_12\",]\n",
    "    file_names =['rawfilter_TRUE' for i in range(0,len(numPc))]\n",
    "    select_columns_bool = True\n",
    "    #select_labels = [\"Raw\"] + [\"MINERVA\" + str(i) for i in range(1,len(numPc))] \n",
    "    select_labels = ['Abx 0-6 months','Abx 6-12 months']\n",
    "    metric_word = \"auc_all\"\n",
    "    chosen_classifier = \"Random Forest\"\n",
    "    title = 'AUC for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "    pair_test_all = False\n",
    "    trans = \"clr_scale\"  \n",
    "    limit_spec =(0.6,0.73)\n",
    "    not_rotate=True\n",
    "    subfile = \"\"\n",
    "\n",
    "if key == \"AGP_abx6_12_calibrate\":\n",
    "    kmer_spec = 5\n",
    "    abx_spec = \"6_12\"\n",
    "    numPc = [0,1,2,3,4,5,6,7,8,9,10] \n",
    "    phen = [\"Abx\" + abx_spec for i in range(len(numPc))]#\" #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"antibiotic history\" + abx_spec \n",
    "    phen_type = \"class\" \n",
    "    \n",
    "    folder_names = [\"AGP_max_k\" + str(kmer_spec) + \"_Abx\" + abx_spec for i in range(len(numPc))]\n",
    "    file_names =['rawfilter_TRUE']+['minerva_first' + str(numPc[i]) + 'filter_TRUE' for i in range(1,len(numPc))]\n",
    "    select_columns_bool = True\n",
    "    #select_labels = [\"Raw\"] + [\"MINERVA\" + str(i) for i in range(1,len(numPc))] \n",
    "    select_labels = numPc\n",
    "    metric_word = \"auc_all\"\n",
    "    chosen_classifier = \"Random Forest\"\n",
    "    title = 'AUC for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "    pair_test_all = False\n",
    "    trans = \"clr_scale\"  \n",
    "    limit_spec =(0.55,0.70)\n",
    "    not_rotate=True\n",
    "    subfile = \"\"\n",
    "if key == \"AGP_abx_calibrate\":\n",
    "    numPc = [0,1,2,3,4,5,6,7,8,9,10] \n",
    "    phen = [\"bin_antibiotic_last_year\" for i in range(len(numPc))]#\" #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"antibiotic history\" \n",
    "    phen_type = \"class\" \n",
    "    \n",
    "    folder_names = [\"AGP_max_k6\" for i in range(len(numPc))]\n",
    "    file_names =['rawfilter_TRUE']+['minerva_first' + str(numPc[i]) + 'filter_TRUE' for i in range(1,len(numPc))]\n",
    "    select_columns_bool = True\n",
    "    #select_labels = [\"Raw\"] + [\"MINERVA\" + str(i) for i in range(1,len(numPc))] \n",
    "    select_labels = numPc\n",
    "    metric_word = \"auc_all\"\n",
    "    chosen_classifier = \"Random Forest\"\n",
    "    title = 'AUC for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "    pair_test_all = False\n",
    "    trans = \"clr_scale\"  \n",
    "    limit_spec =(0.55,0.70)\n",
    "    not_rotate=True\n",
    "    subfile = \"class_pred/\"\n",
    "    \n",
    "\n",
    "if key == \"AGP_abx\":\n",
    "    numPc = [0,0,0,0,2]#,11,12,13,14,15,16,17,18,19,20] \n",
    "    phen = [\"bin_antibiotic_last_year\" for i in range(len(numPc))]#\" #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"antibiotic history\" \n",
    "    phen_type = \"class\" \n",
    "    \n",
    "    folder_names = [\"AGP_max_k6\" for i in range(len(numPc))]\n",
    "    file_names = ['rawfilter_TRUE','bmcfilter_TRUE','ComBatfilter_TRUE','limmafilter_TRUE','minerva_first2filter_TRUE'] \n",
    "    select_columns_bool = True\n",
    "    if simple_minerva_label:\n",
    "        select_labels = [\"Raw\",\"BMC\",\"ComBat\",\"limma\",\"MINERVA\"] #\"Refactor (n. PCs =9)\",\"SmartSVA (n. PCs =3)\",\n",
    "   \n",
    "    else:\n",
    "        select_labels = [\"Raw\",\"BMC\",\"ComBat\",\"limma\",\"MINERVA (n. PCs =2)\"] #\"Refactor (n. PCs =9)\",\"SmartSVA (n. PCs =3)\",\n",
    "    metric_word = \"auc_all\"\n",
    "    chosen_classifier = \"Naive Bayes\"\n",
    "    title = 'AUC for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "    pair_test_all = True\n",
    "    trans = \"clr_scale\"\n",
    "    limit_spec =(0.55,0.68)\n",
    "    shortened=True\n",
    "    not_rotate=False\n",
    "    subfile = \"class_pred/\"\n",
    "if key == \"AGP_BMI_calibrate\":\n",
    "    numPc = [0,1,2,3,4,5,6,7,8,9,10]#,11,12,13,14,15,16,17,18,19,20] \n",
    "    phen = [\"bmi_corrected\" for i in range(len(numPc))]#\" #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"body mass index (BMI)\" #\"antibiotic history\" #\"colorectal cancer status\"#\"bmi\"#\"bmi\"#\"antibiotic history\" #\"colorectal cancer status\"#\"Preterm Birth\"#\"\n",
    "    phen_type = \"cont\" \n",
    "    \n",
    "    folder_names = [\"AGP_max_k6\" for i in range(len(numPc))]\n",
    "    file_names =['rawfilter_TRUE']+['minerva_first' + str(numPc[i]) + 'filter_TRUE' for i in range(1,len(numPc))]\n",
    "    select_columns_bool = True\n",
    "    select_labels = numPc#[\"Raw\"] + [\"MINERVA\" + str(i) for i in range(1,len(numPc))] \n",
    "    metric_word = \"pearson\"\n",
    "    chosen_classifier = \"Naive Bayes\"\n",
    "    title = 'Pearson for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "    pair_test_all = False\n",
    "    trans = \"clr_scale\"\n",
    "    limit_spec =(0.13,0.33)\n",
    "    shortened=True\n",
    "    not_rotate=True\n",
    "    \n",
    "    subfile = \"\"#\"cont_pred/\"\n",
    "    \n",
    "if key == \"AGP_BMI\":\n",
    "    numPc = [0,0,0,0,2]#,11,12,13,14,15,16,17,18,19,20] \n",
    "    phen = [\"bmi_corrected\" for i in range(len(numPc))]#\" #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"body mass index (BMI)\" #\"antibiotic history\" #\"colorectal cancer status\"#\"bmi\"#\"bmi\"#\"antibiotic history\" #\"colorectal cancer status\"#\"Preterm Birth\"#\"\n",
    "    phen_type = \"cont\" \n",
    "    \n",
    "    folder_names = [\"AGP_max_k6\" for i in range(len(numPc))]\n",
    "    file_names = ['rawfilter_TRUE','bmcfilter_TRUE','ComBatfilter_TRUE','limmafilter_TRUE','minerva_first2filter_TRUE'] \n",
    "    select_columns_bool = True\n",
    "    if simple_minerva_label:\n",
    "        select_labels = [\"Raw\",\"BMC\",\"ComBat\",\"limma\",\"MINERVA\"] #\"Refactor (n. PCs =9)\",\"SmartSVA (n. PCs =3)\",\n",
    "    else:\n",
    "        select_labels = [\"Raw\",\"BMC\",\"ComBat\",\"limma\",\"MINERVA (n. PCs =2)\"] #\"Refactor (n. PCs =9)\",\"SmartSVA (n. PCs =3)\",\n",
    "   \n",
    "    metric_word = \"pearson\"\n",
    "    chosen_classifier = \"Naive Bayes\"\n",
    "    title = 'Pearson for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "    pair_test_all = True\n",
    "    trans = \"clr_scale\"\n",
    "    limit_spec =(0.13,0.31)\n",
    "    shortened=True\n",
    "    not_rotate=False\n",
    "    \n",
    "    subfile = \"cont_pred/\"\n",
    "\n",
    "if key == \"Thomas_kmer\":\n",
    "    numPc = [0,0,0,0,4] \n",
    "    phen = [\"bin_crc_adenomaORnormal\" for i in range(len(numPc))]#\" #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"colorectal cancer status\" #\"antibiotic history\" #\"colorectal cancer status\"#\"bmi\"#\"bmi\"#\"antibiotic history\" #\"colorectal cancer status\"#\"Preterm Birth\"#\"\n",
    "    phen_type = \"class\"\n",
    "    \n",
    "    \n",
    "    folder_names = [\"Thomas_k6\" for i in range(len(numPc))]\n",
    "    file_names = ['rawfilter_TRUE','bmcfilter_TRUE','ComBatfilter_TRUE','limmafilter_TRUE','minerva_first4filter_TRUE'] \n",
    "    select_columns_bool = True\n",
    "    if simple_minerva_label:\n",
    "        select_labels = [\"Raw\",\"BMC\",\"ComBat\",\"limma\",\"MINERVA\"] #\"Refactor (n. PCs =9)\",\"SmartSVA (n. PCs =3)\",\n",
    "   \n",
    "    else:\n",
    "        select_labels = [\"Raw\",\"BMC\",\"ComBat\",\"limma\",\"MINERVA (n. PCs =4)\"]\n",
    "    metric_word = \"auc_all\"\n",
    "    chosen_classifier = \"Naive Bayes\"\n",
    "    title = 'AUC for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "    pair_test_all = True\n",
    "    limit_spec =(0.5,0.85)\n",
    "    shortened=True\n",
    "    not_rotate=False\n",
    "if key == \"Thomas_kmer_none_clr\":\n",
    "    numPc = [0,5,0,4] \n",
    "    phen = [\"bin_crc_adenomaORnormal\" for i in range(len(numPc))]#\" #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"colorectal cancer status\" #\"antibiotic history\" #\"colorectal cancer status\"#\"bmi\"#\"bmi\"#\"antibiotic history\" #\"colorectal cancer status\"#\"Preterm Birth\"#\"\n",
    "    phen_type = \"class\"\n",
    "    \n",
    "    \n",
    "    folder_names = [\"Thomas_k6\" for i in range(len(numPc))]\n",
    "    file_names = ['rawfilter_TRUE','rawfilter_TRUE','minerva_first5filter_TRUE','minerva_first4filter_TRUE'] \n",
    "    select_columns_bool = True\n",
    "    select_labels = [\"Raw no trans\",\"Raw clr+scale\",\"MINERVA no trans (n. PCs =5)\",\"MINERVA clr+scale (n. PCs =4)\"]\n",
    "    metric_word = \"auc_all\"\n",
    "    chosen_classifier = \"Naive Bayes\"\n",
    "    title = 'AUC for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "    pair_test_all = True\n",
    "    limit_spec =(0.5,1)\n",
    "    shortened=True\n",
    "    not_rotate=False\n",
    "    shortened_shortened = True\n",
    "    alternate_color = True\n",
    "     \n",
    "    trans = [\"none\",\"clr_scale\",\"none\",\"clr_scale\"]\n",
    "    trans_vec = True\n",
    "if key == \"Thomas_kmer_none_calibrate\":\n",
    "    numPc = [0,1,2,3,4,5,6,7] \n",
    "    phen = [\"bin_crc_adenomaORnormal\" for i in range(len(numPc))]#\"bin_crc_adenomaORnormal\" #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"colorectal cancer status\" #\"antibiotic history\" #\"colorectal cancer status\"#\"bmi\"#\"bmi\"#\"antibiotic history\" #\"colorectal cancer status\"#\"Preterm Birth\"#\"\n",
    "    phen_type = \"class\"\n",
    "    \n",
    "    \n",
    "    folder_names = [\"Thomas_k6\" for i in range(len(numPc))]\n",
    "    file_names =['rawfilter_TRUE']+['minerva_first' + str(numPc[i]) + 'filter_TRUE' for i in range(1,len(numPc))]\n",
    "    select_columns_bool = True\n",
    "    select_labels = numPc \n",
    "    metric_word = \"auc_all\"\n",
    "    chosen_classifier = \"Naive Bayes\"\n",
    "    title = 'AUC for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "    pair_test_all = False\n",
    "    limit_spec =(0.5,0.85)\n",
    "    shortened=True\n",
    "    not_rotate=True\n",
    "    trans_vec = True\n",
    "    trans = [\"none\" for i in range(len(numPc))]\n",
    "\n",
    "if key == \"Thomas_kmer_calibrate\":\n",
    "    numPc = [0,1,2,3,4,5,6,7,8,9,10] \n",
    "    phen = [\"bin_crc_adenomaORnormal\" for i in range(len(numPc))]#\"bin_crc_adenomaORnormal\" #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"colorectal cancer status\" #\"antibiotic history\" #\"colorectal cancer status\"#\"bmi\"#\"bmi\"#\"antibiotic history\" #\"colorectal cancer status\"#\"Preterm Birth\"#\"\n",
    "    phen_type = \"class\"\n",
    "    \n",
    "    \n",
    "    folder_names = [\"Thomas_k6\" for i in range(len(numPc))]\n",
    "    file_names =['rawfilter_TRUE']+['minerva_first' + str(numPc[i]) + 'filter_TRUE' for i in range(1,len(numPc))]\n",
    "    select_columns_bool = True\n",
    "    select_labels = numPc \n",
    "    metric_word = \"auc_all\"\n",
    "    chosen_classifier = \"Naive Bayes\"\n",
    "    title = 'AUC for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "    pair_test_all = False\n",
    "    limit_spec =(0.5,0.85)\n",
    "    shortened=True\n",
    "    not_rotate=True\n",
    "\n",
    "    \n",
    "if key == \"Thomas_Augmentation\":\n",
    "    numPc = [0,0]\n",
    "    phen = \"bin_crc_normal\"# #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_crc_adenomaORnormal\"#\"\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"colorectal cancer status\" #\"antibiotic history\" #\"colorectal cancer status\"#\"bmi\"#\"bmi\"#\"antibiotic history\" #\"colorectal cancer status\"#\"Preterm Birth\"#\"\n",
    "    phen_type = \"class\"#\"class\n",
    "    folder_names = ['CRC_thomas_otu', 'CRC_thomas_otu_DataAugmentation']\n",
    "    file_names = ['rawfilter_TRUE','DataAugmentationfilter_TRUE']\n",
    "    \n",
    "    \n",
    "if key == \"Thomas_otu_calibrate\":    \n",
    "    \n",
    "    numPc = [0,1,2,3,4,5,6,7,8,9,10,11,12,13] \n",
    "    phen = [\"bin_crc_normal\" for i in range(len(numPc))]#\" #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"colorectal cancer status\" #\"antibiotic history\" #\"colorectal cancer status\"#\"bmi\"#\"bmi\"#\"antibiotic history\" #\"colorectal cancer status\"#\"Preterm Birth\"#\"\n",
    "    phen_type = \"class\"\n",
    "    folder_names = [\"CRC_thomas_otu\" for i in range(len(numPc))]\n",
    "    file_names =['rawfilter_TRUE']+['minerva_first' + str(numPc[i]) + 'filter_TRUE' for i in range(1,len(numPc))]\n",
    "    select_columns_bool = True\n",
    "    select_labels = numPc\n",
    "    metric_word = \"auc_all\"\n",
    "    chosen_classifier = \"Random Forest\"\n",
    "    title = 'AUC for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "    pair_test_all = True\n",
    "    limit_spec =(0.4,1)\n",
    "    shortened=True\n",
    "    \n",
    "    not_rotate=True\n",
    "    trans_vec = True\n",
    "    trans = [\"none\" for i in range(len(file_names))]\n",
    "    \n",
    "    \n",
    "if key == \"Thomas_otu\":   \n",
    "    numPc = [0,0,0,0,4] \n",
    "    phen = [\"bin_crc_adenomaORnormal\" for i in range(len(numPc))]#\" #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"colorectal cancer status\" #\"antibiotic history\" #\"colorectal cancer status\"#\"bmi\"#\"bmi\"#\"antibiotic history\" #\"colorectal cancer status\"#\"Preterm Birth\"#\"\n",
    "    phen_type = \"class\"\n",
    "    \n",
    "    folder_names = [\"CRC_Thomas_otu\" for i in range(len(numPc))]\n",
    "    file_names = ['rawfilter_TRUE','bmcfilter_TRUE','ComBatfilter_TRUE','limmafilter_TRUE','minerva_first4filter_TRUE'] \n",
    "    select_columns_bool = True\n",
    "    select_labels = [\"Raw\",\"BMC\",\"ComBat\",\"limma\",\"MINERVA (n. PCs =4)\"]\n",
    "    metric_word = \"auc_all\"\n",
    "    chosen_classifier = \"Naive Bayes\"\n",
    "    title = 'AUC for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "    pair_test_all = True\n",
    "    limit_spec =(0.5,1)\n",
    "    shortened=True\n",
    "    not_rotate=False\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "if key == \"Thomas_mse\":\n",
    "    numPc = [0,0]\n",
    "    phen = \"bin_crc_normal\"# #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_crc_adenomaORnormal\"#\"\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"colorectal cancer status\" #\"antibiotic history\" #\"colorectal cancer status\"#\"bmi\"#\"bmi\"#\"antibiotic history\" #\"colorectal cancer status\"#\"Preterm Birth\"#\"\n",
    "    phen_type = \"cont\"#\"class\"\n",
    "    folder_names = ['CRC_thomas_otu', 'CRC_thomas_otu_PhenCorrect']\n",
    "    file_names = ['rawfilter_TRUE','DataAugmentationfilter_TRUE']\n",
    "\n",
    "if key == \"Gibbons_k_otu\":\n",
    "    numPc = [0,0,150,4]#,11,12,13,14,15,16,17,18,19,20] \n",
    "    phen = [\"bin_crc\",\"bin_crc_normal\",\"bin_crc\",\"bin_crc_normal\" ]#\" #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"colorectal cancer status (normal vs cancer)\" #\"antibiotic history\" #\"colorectal cancer status\"#\"bmi\"#\"bmi\"#\"antibiotic history\" #\"colorectal cancer status\"#\"Preterm Birth\"#\"\n",
    "    \n",
    "    phen_type = \"class\"\n",
    "    \n",
    "    folder_names = [\"CRC_otu\",\"CRC_k7\",\"CRC_otu\",\"CRC_k7\"]\n",
    "    file_names = ['rawfilter_TRUE','rawfilter_TRUE','minerva_first150filter_TRUE','minerva_first4filter_TRUE'] \n",
    "    select_columns_bool = True\n",
    "    select_labels = [\"Raw OTU\",\"Raw 7-mer\",\"MINERVA OTU (n. PCs =150)\",\"MINERVA 7-mer (n. PCs =4)\"] #\"Refactor (n. PCs =9)\",\"SmartSVA (n. PCs =3)\",\n",
    "    metric_word = \"auc_all\"\n",
    "    chosen_classifier = \"Naive Bayes\"\n",
    "    title = 'AUC for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "    pair_test_all = True\n",
    "    trans = \"clr_scale\"\n",
    "    limit_spec =(0.4,1.1)\n",
    "    shortened=True\n",
    "    shortened_shortened=True\n",
    "    not_rotate=False\n",
    "    alternate_color = True\n",
    "    \n",
    "if key == \"Gibbons_calibrate_otu\":\n",
    "    numPc = [0,1,2,3,10,20,40,60,80,100,140,150,200,220,240,260,300]\n",
    "    phen = [\"bin_crc\"  for i in range(len(numPc))]#\" #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"colorectal cancer status (normal vs cancer)\" #\"antibiotic history\" #\"colorectal cancer status\"#\"bmi\"#\"bmi\"#\"antibiotic history\" #\"colorectal cancer status\"#\"Preterm Birth\"#\"\n",
    "    \n",
    "    phen_type = \"class\"\n",
    "    \n",
    "    \n",
    "    folder_names = [\"CRC_otu\" for i in range(len(numPc))]\n",
    "    file_names =['rawfilter_TRUE']+['minerva_first' + str(numPc[i]) + 'filter_TRUE' for i in range(1,len(numPc))]\n",
    "    select_columns_bool = True\n",
    "    #select_labels = [\"Raw\"] + [\"MINERVA\" + str(i) for i in range(1,len(numPc))] \n",
    "    select_labels = numPc\n",
    "    metric_word = \"auc_all\"\n",
    "    chosen_classifier = \"Naive Bayes\"\n",
    "    title = 'AUC for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "    pair_test_all = False\n",
    "    trans = \"clr_scale\"  \n",
    "    limit_spec =(0.4,1)\n",
    "    not_rotate=True\n",
    "    subfile = \"class_pred/\"\n",
    "if key == \"Gibbons_calibrate\":\n",
    "    numPc = [0,1,2,3,4,5,6,7,8,9,10] \n",
    "    phen = [\"bin_crc_adenomaORnormal\"  for i in range(len(numPc))]#\" #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"colorectal cancer status (adenoma/normal vs cancer)\" #\"antibiotic history\" #\"colorectal cancer status\"#\"bmi\"#\"bmi\"#\"antibiotic history\" #\"colorectal cancer status\"#\"Preterm Birth\"#\"\n",
    "    \n",
    "    phen_type = \"class\"\n",
    "    \n",
    "    \n",
    "    folder_names = [\"CRC_k6\" for i in range(len(numPc))]\n",
    "    file_names =['rawfilter_TRUE']+['minerva_first' + str(numPc[i]) + 'filter_TRUE' for i in range(1,len(numPc))]\n",
    "    select_columns_bool = True\n",
    "    #select_labels = [\"Raw\"] + [\"MINERVA\" + str(i) for i in range(1,len(numPc))] \n",
    "    select_labels = numPc\n",
    "    metric_word = \"auc_all\"\n",
    "    chosen_classifier = \"Naive Bayes\"\n",
    "    title = 'AUC for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "    pair_test_all = False\n",
    "    trans = \"clr_scale\"  \n",
    "    limit_spec =(0.4,1)\n",
    "    not_rotate=True\n",
    "    \n",
    "    \n",
    "if key == \"Gibbons\":\n",
    "    numPc = [0,0,0,0,10] \n",
    "    phen = [\"bin_crc_adenomaORnormal\"  for i in range(len(numPc))]#\" #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"colorectal cancer status\" #\"antibiotic history\" #\"colorectal cancer status\"#\"bmi\"#\"bmi\"#\"antibiotic history\" #\"colorectal cancer status\"#\"Preterm Birth\"#\"\n",
    "    phen_type = \"class\"\n",
    "    \n",
    "    \n",
    "    folder_names = [\"CRC_k7\" for i in range(len(numPc))]\n",
    "    \n",
    "    file_names = ['rawfilter_TRUE','bmcfilter_TRUE','ComBatfilter_TRUE','limmafilter_TRUE',\n",
    "             'minerva_first10filter_TRUE']   #['smartsva_first10' + str(numPc[i]) + 'filter_TRUE' for i in range(len(numPc))]\n",
    "    select_columns_bool = True\n",
    "    \n",
    "    if simple_minerva_label:\n",
    "        select_labels = [\"Raw\",\"BMC\",\"ComBat\",\"limma\",\"MINERVA\"] #\"Refactor (n. PCs =9)\",\"SmartSVA (n. PCs =3)\",\n",
    "   \n",
    "    else:\n",
    "        select_labels = [\"Raw\",\"BMC\",\"ComBat\",\"limma\",\"MINERVA (n. PCs =10)\"]#[0,1,2,3,4,5,6,7,8,9,10]#[\"raw\",\"BMC\",\"ComBat\",\"limma\",\"SmartSVA (n. PCs =5)\",\"MINERVA (n. PCs =5)\"]#[0,1,2,3,4,5,6,7,8,9,10]#\n",
    "    \n",
    "   \n",
    "    metric_word = \"auc_all\"\n",
    "    chosen_classifier = \"Naive Bayes\"\n",
    "    title = 'AUC for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "    pair_test_all = True\n",
    "    limit_spec =(0.4,1)\n",
    "    shortened=True\n",
    "    not_rotate=False\n",
    "\n",
    "    \n",
    "if key == \"Gibbons_DataAugment\":\n",
    "    phen = [\"bin_crc_adenomaORnormal\",\"bin_crc_adenomaORnormal\"]#\" #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"colorectal cancer status\" #\"antibiotic history\" #\"colorectal cancer status\"#\"bmi\"#\"bmi\"#\"antibiotic history\" #\"colorectal cancer status\"#\"Preterm Birth\"#\"\n",
    "    phen_type = \"class\"\n",
    "    \n",
    "    numPc = [0,0] \n",
    "    folder_names = [\"CRC_k7\",\"CRC_k7_DataAugmentation\"]\n",
    "    file_names = ['rawfilter_TRUE','DataAugmentationfilter_TRUE']\n",
    "    select_columns_bool = True\n",
    "    metric_word = \"accuracy\"\n",
    "    select_labels = [\"Raw\",\"DataAugmentation\"]#[0,1,2,3,4,5,6,7,8,9,10]#[\"raw\",\"BMC\",\"ComBat\",\"limma\",\"SmartSVA (n. PCs =5)\",\"MINERVA (n. PCs =5)\"]#[0,1,2,3,4,5,6,7,8,9,10]#\n",
    "    chosen_classifier = \"Random Forest\"\n",
    "    title = 'Accuracy for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "    pair_test_all = False\n",
    "    trans = \"clr_scale\"\n",
    "    \n",
    "if key == \"Gibbons_PhenoCorrect_multi\":\n",
    "    phen = [\"bin_crc_adenomaORnormal\",\"bin_crc_adenomaORnormal\"]#\" #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"colorectal cancer status\" #\"antibiotic history\" #\"colorectal cancer status\"#\"bmi\"#\"bmi\"#\"antibiotic history\" #\"colorectal cancer status\"#\"Preterm Birth\"#\"\n",
    "    phen_type = \"class\"\n",
    "    \n",
    "    numPc = [0,0] \n",
    "    folder_names = [\"CRC_k7\",\"CRC_k7_PhenoCorrect\"]\n",
    "    file_names = ['rawfilter_TRUE','PhenoCorrectfilter_TRUE']\n",
    "    select_columns_bool = True\n",
    "    select_labels = [\"Raw\",\"PhenoCorrect\"]#[0,1,2,3,4,5,6,7,8,9,10]#[\"raw\",\"BMC\",\"ComBat\",\"limma\",\"SmartSVA (n. PCs =5)\",\"MINERVA (n. PCs =5)\"]#[0,1,2,3,4,5,6,7,8,9,10]#\n",
    "\n",
    "    metric_word = \"accuracy\"\n",
    "    select_labels = [\"Raw\",\"PhenoCorrection\"]#[0,1,2,3,4,5,6,7,8,9,10]#[\"raw\",\"BMC\",\"ComBat\",\"limma\",\"SmartSVA (n. PCs =5)\",\"MINERVA (n. PCs =5)\"]#[0,1,2,3,4,5,6,7,8,9,10]#\n",
    "    chosen_classifier = \"Random Forest\"\n",
    "    title = 'Accuracy for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "    pair_test_all = False\n",
    "    trans = \"clr_scale\"\n",
    "    \n",
    "    pair_test_all = True\n",
    "    chosen_classifier = \"Random Forest\"\n",
    "    limit_spec =(0.4,0.85)\n",
    "    not_rotate=False\n",
    "    shortened = True\n",
    "    \n",
    "\n",
    "if key == \"Gibbons_PredDomainPheno\":\n",
    "    phen = [\"bin_crc_adenomaORnormal\",\"domain_pheno\"]#\" #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"colorectal cancer status\" #\"antibiotic history\" #\"colorectal cancer status\"#\"bmi\"#\"bmi\"#\"antibiotic history\" #\"colorectal cancer status\"#\"Preterm Birth\"#\"\n",
    "    phen_type = \"class\"\n",
    "    metric_word = 'accuracy'\n",
    "    \n",
    "    numPc = [0,0] \n",
    "    folder_names = [\"CRC_k7\",\"CRC_k7_PredDomainPheno\"]\n",
    "    file_names = ['rawfilter_TRUE','PredDomainPhenofilter_TRUE']\n",
    "    select_columns_bool = True\n",
    "    select_labels = [\"Raw\",\"PredDomainPheno\"]#[0,1,2,3,4,5,6,7,8,9,10]#[\"raw\",\"BMC\",\"ComBat\",\"limma\",\"SmartSVA (n. PCs =5)\",\"MINERVA (n. PCs =5)\"]#[0,1,2,3,4,5,6,7,8,9,10]#\n",
    "    title = 'AUC for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "\n",
    "    \n",
    "if key == \"Wirbel_PredDomainPheno\":\n",
    "    phen = [\"DiseaseState\",\"domain_pheno\"]#\" #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"colorectal cancer status\" #\"antibiotic history\" #\"colorectal cancer status\"#\"bmi\"#\"bmi\"#\"antibiotic history\" #\"colorectal cancer status\"#\"Preterm Birth\"#\"\n",
    "    phen_type = \"class\"\n",
    "    metric_word = 'accuracy'\n",
    "    \n",
    "    numPc = [0,0] \n",
    "    folder_names = [\"CRC_wirbel_otu\",\"CRC_wirbel_otu_PredDomainPheno\"]\n",
    "    file_names = ['rawfilter_TRUE','PredDomainPhenofilter_TRUE']\n",
    "    select_columns_bool = True\n",
    "    select_labels = [\"Raw\",\"PredDomainPheno\"]#[0,1,2,3,4,5,6,7,8,9,10]#[\"raw\",\"BMC\",\"ComBat\",\"limma\",\"SmartSVA (n. PCs =5)\",\"MINERVA (n. PCs =5)\"]#[0,1,2,3,4,5,6,7,8,9,10]#\n",
    "    title = 'AUC for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "    \n",
    "if key == \"Gibbons_PhenoCorrect_reg\":\n",
    "    phen = \"bin_crc_adenomaORnormal\"#\" #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"colorectal cancer status\" #\"antibiotic history\" #\"colorectal cancer status\"#\"bmi\"#\"bmi\"#\"antibiotic history\" #\"colorectal cancer status\"#\"Preterm Birth\"#\"\n",
    "    phen_type = \"cont\"\n",
    "    metric_word = 'pearson'\n",
    "    \n",
    "    numPc = [0,0] \n",
    "    folder_names = [\"CRC_k7\",\"CRC_k7_PhenoCorrect\"]\n",
    "    file_names = ['rawfilter_TRUE','PhenoCorrectfilter_TRUE']\n",
    "    select_columns_bool = True\n",
    "    select_labels = [\"Raw\",\"PhenoCorrect\"]#[0,1,2,3,4,5,6,7,8,9,10]#[\"raw\",\"BMC\",\"ComBat\",\"limma\",\"SmartSVA (n. PCs =5)\",\"MINERVA (n. PCs =5)\"]#[0,1,2,3,4,5,6,7,8,9,10]#\n",
    "    title = 'Pearson for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "    \n",
    "    \n",
    "if key == \"Thomas_PhenoCorrect\":\n",
    "    phen = \"bin_crc_adenomaORnormal\"#\" #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"colorectal cancer status\" #\"antibiotic history\" #\"colorectal cancer status\"#\"bmi\"#\"bmi\"#\"antibiotic history\" #\"colorectal cancer status\"#\"Preterm Birth\"#\"\n",
    "    phen_type = \"class\"\n",
    "    \n",
    "    numPc = [0,0] \n",
    "    folder_names = [\"CRC_thomas_otu\",\"CRC_thomas_otu_PhenoCorrect\"]\n",
    "    file_names =['rawfilter_TRUE']+['PhenoCorrectfilter_TRUE']\n",
    "    select_labels = numPc\n",
    "    metric_word =  'auc_all'\n",
    "if key == \"Thomas_DomainCorrect\":\n",
    "    numPc = [0,0] \n",
    "    phen = [\"bin_crc_adenomaORnormal\" for i in range(len(numPc))]#\" #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"colorectal cancer status\" #\"antibiotic history\" #\"colorectal cancer status\"#\"bmi\"#\"bmi\"#\"antibiotic history\" #\"colorectal cancer status\"#\"Preterm Birth\"#\"\n",
    "    phen_type = \"class\"\n",
    "    \n",
    "    \n",
    "    folder_names = [\"CRC_thomas_otu\" for i in range(len(numPc))]\n",
    "    file_names =['rawfilter_TRUE']+['DomainCorrectfilter_TRUE']\n",
    "    select_labels = file_names\n",
    "    metric_word =  'auc_all'\n",
    "    \n",
    "    \n",
    "    pair_test_all = True\n",
    "    chosen_classifier = \"Random Forest\"\n",
    "    limit_spec =(0.4,0.85)\n",
    "    not_rotate=False\n",
    "    shortened = True\n",
    "    \n",
    "if key == \"T2D\":\n",
    "    numPc = [0,0,0,0,1] \n",
    "    phen = [\"bin_t2d\" for i in range(len(numPc))] #\" #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"diabetes status\" \n",
    "    phen_type = \"class\"\n",
    "    \n",
    "    \n",
    "    folder_names = [\"T2D_k7\" for i in range(len(numPc))]\n",
    "    file_names = ['rawfilter_TRUE','bmcfilter_TRUE','ComBatfilter_TRUE','limmafilter_TRUE'\n",
    "                  ,'minerva_first1filter_TRUE']   #['smartsva_first10' + str(numPc[i]) + 'filter_TRUE' for i in range(len(numPc))]\n",
    "    select_columns_bool = True\n",
    "    if simple_minerva_label:\n",
    "        select_labels = [\"Raw\",\"BMC\",\"ComBat\",\"limma\",\"MINERVA\"] #\"Refactor (n. PCs =9)\",\"SmartSVA (n. PCs =3)\",\n",
    "   \n",
    "    else:\n",
    "        select_labels = [\"Raw\",\"BMC\",\"ComBat\",\"limma\", \"MINERVA (n. PCs =1)\"]\n",
    "    \n",
    "    metric_word =  'auc_all'\n",
    "    title = 'AUC for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "    pair_test_all = True\n",
    "    chosen_classifier = \"Random Forest\"\n",
    "    limit_spec =(0.4,0.85)\n",
    "    not_rotate=False\n",
    "    shortened = True\n",
    "    \n",
    "if key == \"T2D_calibrate\":\n",
    "\n",
    "\n",
    "    numPc = [0,1,2,3,4,5,6,7,8,9,10] \n",
    "    phen = [\"bin_t2d\" for i in range(len(numPc))]#\" #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"diabetes status\" #\"antibiotic history\" #\"colorectal cancer status\"#\"bmi\"#\"bmi\"#\"antibiotic history\" #\"colorectal cancer status\"#\"Preterm Birth\"#\"\n",
    "    phen_type = \"class\"\n",
    "    \n",
    "    \n",
    "    folder_names = [\"T2D_k7\" for i in range(len(numPc))]\n",
    "    file_names =['rawfilter_TRUE']+['minerva_first' + str(numPc[i]) + 'filter_TRUE' for i in range(1,len(numPc))]\n",
    "    select_columns_bool = True\n",
    "    select_labels = numPc#[\"Raw\"] + [\"Refactor\" + str(i) for i in range(1,len(numPc))] \n",
    "    metric_word = \"auc_all\"\n",
    "    chosen_classifier = \"Random Forest\"\n",
    "    title = 'AUC for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "    pair_test_all = False\n",
    "    limit_spec =(0.4,0.83)\n",
    "    not_rotate=True\n",
    "    \n",
    "#[0,1,2,3,10,20,40,60,80,100,140,150,200,220,240,260,300]#[0,1,2,3,10,20,30,40,50, 60, 70, 80 ,10]#\n",
    "lin_model = \"reg\"\n",
    "if not trans_vec:\n",
    "    trans = [\"clr_scale\" for i in range(len(file_names))]\n",
    "data_type = \"kmer\"\n",
    " #[0,0,0,0,1,1]#\n",
    "#[0,1,2,3,4,5,6,7,8,9,10]#[0,0,0,0,5,5]#[0,1,2,3,4,5,6,7,8,9,10]##[20,30,40,50,60,70,80,90,100,110,120,130,150,200]#[0,0,0,0,3,1,2]#[0,1,2,3,4,5,6,7,8,9,10]###,20,30,40,50,100,120,140] #[0,0,0,0,10,10,1] # [0\n",
    "#[key_folder for i in range(len(numPc))]\n",
    "#folder_names = [key_folder for i in range(len(numPc))]\n",
    "#folder_names = ['AGP_max_k6_subsample_' + str(i) + '_seed_1' for i in [20,40,60,80]]\n",
    "#['CRC_k6' for i in range(len(numPc))]#\n",
    "# [\"AGP_max_k5\",\"AGP_max_k6\",\"AGP_max_k7\"]#,\"AGP_max_k8\"]#['AGP_max_k7' for i in range(len(numPc))]\n",
    "#file_names = ['rawfilter_TRUE','smartsva_first2filter_TRUE','minerva_first2filter_TRUE']   #['smartsva_first10' + str(numPc[i]) + 'filter_TRUE' for i in range(len(numPc))]\n",
    "\n",
    "#file_names = ['rawfilter_TRUE']+['mine3rva_first' + str(numPc[i]) + 'filter_TRUE' for i in range(1,len(numPc))] \n",
    "#+['smartsva_first' + str(numPc[i]) + 'filter_TRUE' for i in range(1,len(numPc))]\n",
    "\n",
    "#file_names =['rawfilter_TRUE']+['minerva_plus_first' + str(numPc[i]) + 'filter_TRUE' for i in range(1,4)] + ['minerva_first' + str(numPc[i]) + 'filter_TRUE' for i in range(4,7)] \n",
    "#file_names =['rawfilter_TRUE']+['smartsva_first' + str(numPc[i]) + 'filter_TRUE' for i in range(1,len(numPc))] \n",
    "#file_names =['rawfilter_TRUE' for i in range(0,len(numPc))] \n",
    "\n",
    "#file_names =['rawfilter_TRUE']+['smartsva_first' + str(numPc[i]) + 'filter_TRUE' for i in range(1,len(numPc))]\n",
    "#file_names = ['rawfilter_TRUE']+['smartsva_first' + str(numPc[i]) + 'filter_TRUE' for i in range(1,len(numPc))]\n",
    "# #\n",
    "\n",
    "# file_names = ['rawfilter_TRUE','bmcfilter_TRUE','ComBatfilter_TRUE','limmafilter_TRUE',\n",
    "#              'smartsva_first7filter_TRUE','minerva_first6filter_TRUE']   #['smartsva_first10' + str(numPc[i]) + 'filter_TRUE' for i in range(len(numPc))]\n",
    "#'bmcfilter_TRUE','limmafilter_TRUE', ''refactor_first2filter_TRUE',\n",
    "#file_names = ['rawfilter_TRUE','ComBatfilter_TRUE','bmcfilter_TRUE','limmafilter_TRUE', 'smartsva_first6filter_TRUE','refactor_first7filter_TRUE','minerva_first7filter_TRUE']   #['smartsva_first10' + str(numPc[i]) + 'filter_TRUE' for i in range(len(numPc))]\n",
    "#file_names = ['rawfilter_TRUE']+ ['smartsva_first' + str(numPc[i]) + 'filter_TRUE' for i in range(1,len(numPc))]\n",
    "#file_names = ['rawfilter_TRUE']+ ['refactor_first' + str(numPc[i]) + 'filter_TRUE' for i in range(1,len(numPc))]\n",
    "\n",
    "file_names = [file_names[f] + \"_trans_\" + trans[f] for f in range(len(file_names))]\n",
    "nice_names = [\"7\" + '-mer' for i in range(len(numPc))]\n",
    "\n",
    "# file_names =[ 'kmer_BatchCorrected_antibiotic_classification_auc',\n",
    "#              'kmer_BatchCorrected_antibiotic_classification_auc',\n",
    "#              'kmer_BatchCorrected_antibiotic_classification_auc',\n",
    "#             'kmer_BatchCorrected_antibiotic_classification_auc']\n",
    "#folder_names = ['AGP_Hfilter_k5/robust_k','AGP_Hfilter_k6/robust_k','AGP_Hfilter_k7/robust_k','AGP_Hfilter_k8/robust_k']\n",
    "\n",
    "#folder_names = ['AGP_otumatch_otu','AGP_otumatch_k7','AGP_otumatch_k7'] #,'AGP_otumatch_k7']#['AGP_healthymax_k6', 'AGP_healthymax_k7']\n",
    "#['AGP_otumatch_otu','AGP_otumatch_k7','AGP_otumatch_k7']\n",
    "#['AGP_healthymax_k6', 'AGP_healthymax_k7']\n",
    "#nice_names = [\"5-mer\",\"6-mer\",\"7-mer\",\"8-mer\"] #,\"KMER\"]#, 'KMER old batch correct','KMER MINERVA']\n",
    "\n",
    "if phen_type == \"cont\":\n",
    "    \n",
    "    metric_word = 'pearson' # 'auc_all'#'pearson' # 'auc_all'#''auc_all' # 'pearson' # \n",
    "    classifier_name = 'bmi_prediction' #'bin_antibiotic_last_year'### #'bin_omnivore_diet'#'' 'bin_antibiotic_last_year'# #'Naive Bayes' #'\n",
    "    classifier = 'Regression'# \"Random Forest\"##\"Random Forest\"#'Regression'#\"Random Forest\"\n",
    "    classifier_ofc = \"Lin\"\n",
    "    title = 'Pearson correlation of ' + phen_pretty# 'AUC for prediction of antibiotic history'#'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "    special_name = phen[0] #\"Antibiotic history class prediction\"#\"Antibiotic history class prediction\"#\"BMI prediction\" #\"Antibiotic history class prediction\"#\"BMI prediction\"# \"Antibody prediction\"# \n",
    "else:\n",
    "    #'pearson' # 'auc_all'#''auc_all' # 'pearson' # \n",
    "    classifier_name = 'bin_antibiotic_last_year'### #'bin_omnivore_diet'#'' 'bin_antibiotic_last_year'# #'Naive Bayes' #'\n",
    "    classifier_ofc = \"Mixed\"\n",
    "    classifier = [chosen_classifier for f in file_names]#\"Naive Bayes\"#\"\"Naive Bayes\"#Random Forest\"#Random Forest\"#\"#'Regression'#\"Random Forest\"\n",
    "\n",
    "    #title = 'AUC for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "    special_name = phen[0] #\"Antibiotic history class prediction\"#\"BMI prediction\" #\"Antibiotic history class prediction\"#\"BMI prediction\"# \"Antibody prediction\"# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metric = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bin_crc_normal',\n",
       " 'bin_crc_normal',\n",
       " 'bin_crc_normal',\n",
       " 'bin_crc_normal',\n",
       " 'bin_crc_normal']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/leahbriscoe/Documents/MicroBatch/microbatch_vc/data/CRC_k7/kmer_BatchCorrected_bin_crc_normal_raw_grid_trans_none_classification_auc.pkl\n",
      "/Users/leahbriscoe/Documents/MicroBatch/microbatch_vc/data/CRC_k7/kmer_BatchCorrected_bin_crc_normal_ComBat_grid_trans_none_classification_auc.pkl\n",
      "/Users/leahbriscoe/Documents/MicroBatch/microbatch_vc/data/CRC_k7/kmer_BatchCorrected_bin_crc_normal_limma_grid_trans_none_classification_auc.pkl\n",
      "/Users/leahbriscoe/Documents/MicroBatch/microbatch_vc/data/CRC_k7/kmer_BatchCorrected_bin_crc_normal_MINERVA_grid_trans_none_classification_auc.pkl\n",
      "not file\n",
      "MINERVA_grid_trans_none\n",
      "/Users/leahbriscoe/Documents/MicroBatch/microbatch_vc/data/CRC_k7/kmer_BatchCorrected_bin_crc_normal_MINERVA_grid_trans_clr_scale_classification_auc.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for f in range(len(file_names)):\n",
    "    \n",
    "    if metric_word == 'pearson':\n",
    "        if add_linmodel_type:\n",
    "            \n",
    "            filename_temp = data_folder + folder_names[f] +\"/\" + subfile + data_type + \"_BatchCorrected_\" + phen[f] + \"_\"+ file_names[f] + \"_lin_model_\" + lin_model +\"_pearson_and_mse.pkl\"\n",
    "        \n",
    "        else:\n",
    "            # \"_lin_model_\" + lin_model +\n",
    "            filename_temp = data_folder + folder_names[f] +\"/\" + subfile + data_type + \"_BatchCorrected_\" + phen[f] + \"_\"+ file_names[f] + \"_pearson_and_mse.pkl\"\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        filename_temp = data_folder + folder_names[f] + \"/\" +subfile + data_type + \"_BatchCorrected_\"+ phen[f] + \"_\" + file_names[f] + \"_classification_auc.pkl\"\n",
    "    print(filename_temp)\n",
    "    if os.path.isfile(filename_temp):\n",
    "        \n",
    "        data_temp = pickle.load( open( filename_temp ,\"rb\"))\n",
    "    \n",
    "        #methods_lists.append([k for k in data1.keys()]) \n",
    "        \n",
    "        if metric_word == \"auc_all\" or metric_word == \"accuracy\":\n",
    "            index = folder_names[f] + file_names[f]\n",
    "            #index = folder_names[f]\n",
    "            #index = nice_names[f] + \"_first_\" + str(numPc[f])\n",
    "            \n",
    "            df_metric[index] = pd.Series(data_temp[file_names[f]][classifier[f]][metric_word])\n",
    "            #nice_names[f] + \"_first_\" + str(numPc[f])\n",
    "        else:\n",
    "            #index = folder_names[f] + file_names[f]\n",
    "            index = file_names[f]\n",
    "            df_metric[index] = pd.Series(data_temp[metric_word])\n",
    "    else:\n",
    "        print(\"not file\")\n",
    "        print(file_names[f])\n",
    "        df_metric[nice_names[f] + file_names[f]] = 0\n",
    "        df_metric[nice_names[f] + file_names[f]] = 0\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metric.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "#delta = np.array(df_metric.iloc[:,4]-df_metric.iloc[:,0])\n",
    "#print(np.mean(delta))\n",
    "#print(scipy.stats.sem(delta))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRC_k7raw_grid_trans_none</th>\n",
       "      <th>CRC_k7ComBat_grid_trans_none</th>\n",
       "      <th>CRC_k7limma_grid_trans_none</th>\n",
       "      <th>7-merMINERVA_grid_trans_none</th>\n",
       "      <th>CRC_k7MINERVA_grid_trans_clr_scale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.821480</td>\n",
       "      <td>0.816159</td>\n",
       "      <td>0.757136</td>\n",
       "      <td>0</td>\n",
       "      <td>0.821991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.712627</td>\n",
       "      <td>0.717949</td>\n",
       "      <td>0.721819</td>\n",
       "      <td>0</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.702951</td>\n",
       "      <td>0.708757</td>\n",
       "      <td>0.709724</td>\n",
       "      <td>0</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.742622</td>\n",
       "      <td>0.736817</td>\n",
       "      <td>0.735849</td>\n",
       "      <td>0</td>\n",
       "      <td>0.692550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.764676</td>\n",
       "      <td>0.757591</td>\n",
       "      <td>0.765688</td>\n",
       "      <td>0</td>\n",
       "      <td>0.794872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CRC_k7raw_grid_trans_none  CRC_k7ComBat_grid_trans_none  \\\n",
       "0                   0.821480                      0.816159   \n",
       "1                   0.712627                      0.717949   \n",
       "2                   0.702951                      0.708757   \n",
       "3                   0.742622                      0.736817   \n",
       "4                   0.764676                      0.757591   \n",
       "\n",
       "   CRC_k7limma_grid_trans_none  7-merMINERVA_grid_trans_none  \\\n",
       "0                     0.757136                             0   \n",
       "1                     0.721819                             0   \n",
       "2                     0.709724                             0   \n",
       "3                     0.735849                             0   \n",
       "4                     0.765688                             0   \n",
       "\n",
       "   CRC_k7MINERVA_grid_trans_clr_scale  \n",
       "0                            0.821991  \n",
       "1                            0.812500  \n",
       "2                            0.750000  \n",
       "3                            0.692550  \n",
       "4                            0.794872  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3.216766\n",
       "1    2.964895\n",
       "2    2.871432\n",
       "3    2.907837\n",
       "4    3.082827\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metric.sum(axis=1)\n",
    "#df_metric.sort_values('OTUraw')\n",
    "#In this example, there are NO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['raw_grid_trans_none',\n",
       " 'ComBat_grid_trans_none',\n",
       " 'limma_grid_trans_none',\n",
       " 'MINERVA_grid_trans_none',\n",
       " 'MINERVA_grid_trans_clr_scale']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_columns = df_metric.columns #[ i + 'clr_pca_regress_out_no_scale_first10' for i in nice_names ] \n",
    "#select_labels = [\"raw\",\"ComBat\",\"BMC\",\"limma\",\"SmartSVA\",\"Refactor\",\"MINERVA\"]\n",
    "#select_labels = numPc\n",
    "#select_labels = [\"raw\",\"MINERVA\",\"Refactor\",\"SmartSVA\"]\n",
    "\n",
    "\n",
    "# ['Refactor CLR 100 SVs','Refactor CLR 220 SVs','MINERVA 100 SVs','MINERVA 220 SVs', \n",
    "#                  \"Refactor 120 SVs\", \"SmartSVA CLR 220 SVs\",\"SmartSVA 120 SVs\"]\n",
    "\n",
    "# select_labels = [\"MINERVA no std 10 SVs\", \"MINERVA std 10 SVs\",\"SmartSVA 10 SVs\", \n",
    "#                  \"MINERVA no std 5 SVs\", \"MINERVA std 5 SVs\",\"SmartSVA 5 SVs\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#[ i + ' MINERVA' for i in nice_names ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ['6-mers norm', '6-mers no_scale_clr','6-mers scale_clr','7-mers norm','7-mers no_scale_clr','7-mers scale_clr']\n",
    "# ['6-mers Raw', '6-mers MINVERVA','6-mers MINERVA-scale', '7-mers Raw','7-mers MINVERVA','7-mers MINVERVA-scale']\n",
    "# Make boxplot for one group only\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# select_columns = ['7-merclr_pca_regress_out_no_scale_first10filter_FALSE',\n",
    "#        '7-merclr_pca_regress_out_scale_first10filter_FALSE',\n",
    "#        '7-mersmartsva_first10filter_FALSE',\n",
    "#        '7-merclr_pca_regress_out_no_scale_first5filter_FALSE',\n",
    "#        '7-merclr_pca_regress_out_scale_first5filter_FALSE',\n",
    "#        '7-mersmartsva_first5filter_FALSE']\n",
    "\n",
    "# select_labels = [\"KMER MINERVA \"]\n",
    "\n",
    "# select_columns = ['OTUraw','OTUbmc','OTUComBat','OTUlimma',\n",
    "#                                  'KMERraw','KMERbmc','KMERComBat','KMERlimma',\n",
    "#                   \"KMERsmartsva_first10\",\"KMERrefactor_first10\",\n",
    "#                  \"KMERno_scale_clr\"]\n",
    "\n",
    "# select_columns = ['OTUraw','OTUbmc','OTUComBat','OTUlimma','KMERraw',\n",
    "#                   'KMERbmc','KMERComBat','KMERlimma',\"KMERsmartsva_first10\",\n",
    "#                   \"KMERrefactor_first10\", \"KMERclr_pca_regress_out_no_scale_first10\"]\n",
    "\n",
    "# select_columns = ['OTUraw','OTUbmc','OTUComBat','OTUlimma',\n",
    "#                                  'KMERraw','KMERbmc','KMERComBat','KMERlimma',\n",
    "#                   \"KMERsmartsva_first10\",\"KMERrefactor_first10\",\n",
    "#                  \"KMERno_scale_clr\"] #clr_pca_regress_out_no_scale_first10\n",
    "\n",
    "# ['OTUraw','OTUbmc','OTUComBat','OTUlimma',\n",
    "#                                  'OTUclr_pca_regress_out_no_scale',\"KMERnorm\",\"KMERno_scale_clr\"]\n",
    "\n",
    "# select_labels = ['OTU raw','OTU BMC','OTU ComBat','OTU limma',\n",
    "#                                      \"K-mer raw\",\"K-mer BMC\", \"K-mer ComBat\",\n",
    "#                 \"K-mer limma\",\"K-mer smartsva\",\"K-mer refactor\",\"K-mer MINERVA\"]\n",
    "#['OTU raw','OTU BMC','OTU ComBat','OTU limma',\"OTU MINERVA\",\"K-mer raw\", \"K-mer MINERVA\"]\n",
    "\n",
    "\n",
    "# ['OTU raw','OTU BMC','OTU ComBat','OTU limma',\n",
    "#                                      \"K-mer raw\",\"K-mer ComBat\",\"K-mer smartsva*\",\n",
    "#                                     \"K-mer MINERVA\"]\n",
    "sns.set_style(\"whitegrid\")\n",
    "if select_columns_bool:\n",
    "    \n",
    "    #plot_color[0:4] + [plot_color[7]] + [plot_color[4]] + [plot_color[7]\n",
    "    if not_rotate:\n",
    "        \n",
    "        current_palette = sns.color_palette()\n",
    "        #sns.palplot(current_palette)\n",
    "        #palette = sns.cubehelix_palette(df_metric.shape[1])\n",
    "        palette = sns.color_palette(\"Blues\", df_metric.shape[1])\n",
    "        plot_color = palette.as_hex()\n",
    "        \n",
    "        \n",
    "        \n",
    "        g=sns.boxplot( data = df_metric[select_columns],palette=plot_color)\n",
    "        g.set_xticklabels(labels = select_labels) #df_metric.columns\n",
    "    else:\n",
    "        \n",
    "        \n",
    "        current_palette = sns.color_palette()\n",
    "        #sns.palplot(current_palette)\n",
    "        #palette = sns.cubehelix_palette(df_metric.shape[1])\n",
    "        if not alternate_color:\n",
    "            #palette = sns.color_palette(\"Reds\", df_metric.shape[1]-1)\n",
    "            #plot_color = palette.as_hex()[::-1] + [\"#0093FF\"]#[\"#01d3e8\"]\n",
    "            \n",
    "            #palette = sns.color_palette(\"Reds\", 2)\n",
    "            #reds_color = palette.as_hex()[1:2]\n",
    "            \n",
    "            #palette = sns.color_palette(\"Oranges\", df_metric.shape[1]-2)\n",
    "            #oranges_color = palette.as_hex()\n",
    "            \n",
    "            #plot_color = reds_color + oranges_color +[\"#0093FF\"]\n",
    "            \n",
    "            \n",
    "            plot_color =['#e32f27','#FF9300','#FFE800','#fdd0a2',\"#0093FF\"]\n",
    "        else:\n",
    "            palette1 = sns.color_palette(\"Reds\", 2) [::-1] \n",
    "            palette2 = sns.color_palette(\"Blues\", 2)\n",
    "            plot_color = palette1.as_hex() + palette2.as_hex()\n",
    "            \n",
    "        g=sns.boxplot( data = df_metric[select_columns],palette=plot_color)\n",
    "        g.set_xticklabels(rotation=90,labels = select_labels) #df_metric.columns\n",
    "else:\n",
    "    g=sns.boxplot( data = df_metric)\n",
    "    g.set_xticklabels(rotation=90,labels = df_metric.columns)\n",
    "g.set(ylim=limit_spec)\n",
    "\n",
    "g.set_title(title)\n",
    "\n",
    "asterisk = [\"ns\",\"*\",\"**\",\"***\",\"****\"]\n",
    "\n",
    "#g=sns.boxplot( data = df_metric[select_columns],palette=plot_color)\n",
    "  \n",
    "# box_pairs=[(df_metric.columns[0], df_metric.columns[1]),\n",
    "#                                       (df_metric.columns[0], df_metric.columns[2]),\n",
    "#                                       (df_metric.columns[0], df_metric.columns[3]),\n",
    "#                                       (df_metric.columns[0], df_metric.columns[4])]\n",
    "# for a,b in box_pairs:\n",
    "#     print(a,b)\n",
    "#     t_stat = scipy.stats.ttest_rel(df_metric[a],df_metric[b], axis=0, nan_policy='propagate')\n",
    "#     print(t_stat.pvalue)\n",
    "#     if t_stat.pvalue < 0.05:\n",
    "#         ax.text(x=1, y=1, s=asterisk[0], va='center') \n",
    "\n",
    "if not_rotate:\n",
    "    \n",
    "    ref_col = df_metric.iloc[:,0]\n",
    "    tick_vec = g.get_xticks()[1:]\n",
    "else:\n",
    "    ref_col = df_metric.iloc[:,4]\n",
    "    tick_vec = g.get_xticks()[:-1]\n",
    "\n",
    "vertical_offset = 0.05\n",
    "for xtick in tick_vec:\n",
    "    \n",
    "    compare_col = df_metric.iloc[:,xtick]\n",
    "    median = np.max(compare_col)\n",
    "    \n",
    "    \n",
    "    t_res = ttest_rel(ref_col, compare_col)\n",
    "    p = t_res.pvalue\n",
    "\n",
    "    \n",
    "    if p > 5.00e-02 and p <= 1.00e+00:\n",
    "        asterisk_index = 0\n",
    "    elif 1.00e-02 < p  and p <= 5.00e-02:\n",
    "        asterisk_index = 1\n",
    "    elif 1.00e-03 < p and p <= 1.00e-02:\n",
    "        asterisk_index = 2\n",
    "    elif 1.00e-04 < p <= 1.00e-03:\n",
    "        asterisk_index = 3\n",
    "    elif p <= 1.00e-04:\n",
    "        asterisk_index = 4\n",
    "        \n",
    "        \n",
    "    \n",
    "    g.text(xtick,median + vertical_offset,asterisk[asterisk_index], \n",
    "            horizontalalignment='center',size='large',color='black',weight='semibold')\n",
    "    \n",
    "\n",
    "\n",
    "g.yaxis.grid(False)\n",
    "if metric_word== \"pearson\":\n",
    "    g.set(xlabel=\"Method\", ylabel = \"Pearson Correlation\")\n",
    "else:\n",
    "    g.set(xlabel=\"Method\", ylabel = \"AUC\")\n",
    "\n",
    "plt.savefig(plot_folder + chosen_classifier + data_type + \"_\" + trans[0] + '_boxplots_' + classifier_ofc + '_' + metric_word + \"_\" + special_name + '.pdf',bbox_inches='tight')\n",
    "plt.savefig(plot_folder + chosen_classifier + data_type + \"_\" + trans[0] +  '_boxplots_' + classifier_ofc + '_' + metric_word + \"_\" + special_name + '.png',bbox_inches='tight')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_rotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#e32f27', '#FF9300', '#FFE800', '#fdd0a2', '#0093FF']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRC_k7raw_grid_trans_none             0.748871\n",
       "CRC_k7ComBat_grid_trans_none          0.747454\n",
       "CRC_k7limma_grid_trans_none           0.738043\n",
       "7-merMINERVA_grid_trans_none          0.000000\n",
       "CRC_k7MINERVA_grid_trans_clr_scale    0.774382\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metric.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value annotation legend:\n",
      "ns: 5.00e-02 < p <= 1.00e+00\n",
      "*: 1.00e-02 < p <= 5.00e-02\n",
      "**: 1.00e-03 < p <= 1.00e-02\n",
      "***: 1.00e-04 < p <= 1.00e-03\n",
      "****: p <= 1.00e-04\n",
      "\n",
      "CRC_k7raw_grid_trans_none v.s. CRC_k7ComBat_grid_trans_none: t-test independent samples with Bonferroni correction, P_val=1.000e+00 stat=4.965e-02\n",
      "CRC_k7raw_grid_trans_none v.s. CRC_k7limma_grid_trans_none: t-test independent samples with Bonferroni correction, P_val=1.000e+00 stat=4.579e-01\n",
      "CRC_k7raw_grid_trans_none v.s. 7-merMINERVA_grid_trans_none: t-test independent samples with Bonferroni correction, P_val=1.802e-09 stat=3.534e+01\n",
      "CRC_k7raw_grid_trans_none v.s. CRC_k7MINERVA_grid_trans_clr_scale: t-test independent samples with Bonferroni correction, P_val=1.000e+00 stat=-7.985e-01\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statannot import add_stat_annotation\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "\n",
    "x = \"Method\"\n",
    "y = \"AUC\"\n",
    "order = ['Sun', 'Thur', 'Fri', 'Sat']\n",
    "ax = sns.boxplot(data=df_metric,palette=plot_color)\n",
    "sns.set_context(\"paper\", font_scale=1.5) \n",
    "sns.set_style(\"whitegrid\")\n",
    "if pair_test_all:\n",
    "    if shortened:\n",
    "        if shortened_shortened:\n",
    "            add_stat_annotation(ax, data=df_metric,\n",
    "                        box_pairs=[(df_metric.columns[0], df_metric.columns[1]),\n",
    "                                  (df_metric.columns[0], df_metric.columns[2]),\n",
    "                                  (df_metric.columns[0], df_metric.columns[3]),\n",
    "                                  (df_metric.columns[2], df_metric.columns[3])],\n",
    "                        test='t-test_ind', text_format='star', loc='outside', verbose=2)\n",
    "        else:\n",
    "            if key == 'Gibbons':\n",
    "                add_stat_annotation(ax, data=df_metric,\n",
    "                            box_pairs=[(df_metric.columns[0], df_metric.columns[1]),\n",
    "                                      (df_metric.columns[0], df_metric.columns[2]),\n",
    "                                      (df_metric.columns[0], df_metric.columns[3]),\n",
    "                                      (df_metric.columns[0], df_metric.columns[4]),\n",
    "                                       (df_metric.columns[1], df_metric.columns[4])],\n",
    "                            test='t-test_ind', text_format='star', loc='outside', verbose=2)\n",
    "            else:\n",
    "                add_stat_annotation(ax, data=df_metric,\n",
    "                            box_pairs=[(df_metric.columns[0], df_metric.columns[1]),\n",
    "                                      (df_metric.columns[0], df_metric.columns[2]),\n",
    "                                      (df_metric.columns[0], df_metric.columns[3]),\n",
    "                                      (df_metric.columns[0], df_metric.columns[4])],\n",
    "                            test='t-test_ind', text_format='star', loc='outside', verbose=2)\n",
    "\n",
    "    else:\n",
    "        add_stat_annotation(ax, data=df_metric,\n",
    "                        box_pairs=[(df_metric.columns[0], df_metric.columns[1]),\n",
    "                                  (df_metric.columns[0], df_metric.columns[2]),\n",
    "                                  (df_metric.columns[0], df_metric.columns[3]),\n",
    "                                  (df_metric.columns[0], df_metric.columns[4]),\n",
    "                                  (df_metric.columns[0], df_metric.columns[5]),\n",
    "                                  (df_metric.columns[0], df_metric.columns[6])],\n",
    "                        test='t-test_ind', text_format='star', loc='outside', verbose=2)\n",
    "\n",
    "else:\n",
    "    add_stat_annotation(ax, data=df_metric,\n",
    "                    box_pairs=[(df_metric.columns[0], df_metric.columns[11])],\n",
    "                    test='t-test_paired', text_format='star', loc='outside', verbose=2)\n",
    "# , (df_metric.columns[0], df_metric.columns[5])\n",
    "if not_rotate:\n",
    "    ax.set_xticklabels(labels = select_labels)\n",
    "else:\n",
    "    ax.set_xticklabels(rotation=90,labels = select_labels)\n",
    "ax.set(ylim=limit_spec)\n",
    "ax.set_title(title)\n",
    "plt.savefig(plot_folder + chosen_classifier + data_type + \"_\" + trans[0] + '_boxplots_' + classifier_ofc + '_' + metric_word + \"_\" + special_name + '_2.pdf',bbox_inches='tight')\n",
    "#(df_metric.columns[0], df_metric.columns[2]),\n",
    "#                              (df_metric.columns[0], df_metric.columns[3]),\n",
    "#                             (df_metric.columns[0], df_metric.columns[4]),\n",
    "#                             (df_metric.columns[0], df_metric.columns[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0087514570372074"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(df_metric.sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0087514570372074"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.array(df_metric.sum(axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df_metric.sum(axis=0)\n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRC_k7raw_grid_trans_none             3.744357\n",
       "CRC_k7ComBat_grid_trans_none          3.737272\n",
       "CRC_k7limma_grid_trans_none           3.690217\n",
       "7-merMINERVA_grid_trans_none          0.000000\n",
       "CRC_k7MINERVA_grid_trans_clr_scale    3.871912\n",
       "dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(np.isnan(df_metric.sum(axis=0)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
