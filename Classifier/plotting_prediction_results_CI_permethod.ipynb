{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy.stats import ttest_rel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = '/Users/leahbriscoe/Documents/MicroBatch/microbatch_vc/data/'\n",
    "plot_folder = '/Users/leahbriscoe/Documents/MicroBatch/microbatch_vc/plots/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_names =[ 'kmer_BatchCorrected_bmi_corrected_pearson_and_mse',\n",
    "#              'kmer_BatchCorrected_bmi_corrected_pearson_and_mse',\n",
    "#              'kmer_BatchCorrected_bmi_corrected_pearson_and_mse',\n",
    "#              'kmer_BatchCorrected_bmi_corrected_pearson_and_mse']\n",
    "             #'kmer_BatchCorrected_bmi_corrected_pearson_and_mse']\n",
    "\n",
    "    #'otu_BatchCorrected_bmi_corrected_pearson_and_mse'\n",
    "#'kmer_kmer_table_bmi_corrected_pearson_and_mse',\n",
    "\n",
    "#['bmi_corrected_pearson_and_mse','bmi_corrected_pearson_and_mse']\n",
    "# folder_names = ['AGP_Hfilter_otu','AGP_Hfilter_k6/robust_k','AGP_Hfilter_k7/robust_k']\n",
    "# file_names =[ 'otu_BatchCorrected_antibiotic_classification_auc',\n",
    "#              'kmer_BatchCorrected_antibiotic_classification_auc',\n",
    "#              'kmer_BatchCorrected_antibiotic_classification_auc']\n",
    "\n",
    "# nice_names = [\"OTU\",\"KMER\",\"KMER\"]\n",
    "\n",
    "#select_labels =[\"Raw\",\"Phen Correct\"]#[\"raw\",\"BMC\",\"ComBat\",\"limma\",\"SmartSVA (n. PCs =7)\",\"MINERVA (n. PCs =6)\"]#[0,1,2,3,4,5,6,7,8,9,10]#[\"raw\",\"BMC\",\"ComBat\",\"limma\",\"SmartSVA (n. PCs =5)\",\"MINERVA (n. PCs =5)\"]#[0,1,2,3,4,5,6,7,8,9,10]#\n",
    "#[\"raw\",\"MINERVA+ (n. PCs =8)\", \"MINERVA+ (n. PCs =9)\",\"MINERVA+ (n. PCs =10)\",\"MINERVA (n. PCs =8)\",\"MINERVA (n. PCs =9)\",\"MINERVA (n. PCs =10)\"]# [\"raw\",\"ComBat\",\"limma\",\"SmartSVA (n. PCs =10)\",\"MINERVA (n. PCs =10)\"]##[0.20,0.40,0.60,0.80]#[\"raw\",\"ComBat\",\"BMC\",\"limma\",\"SmartSVA (n. PCs =1)\",\"MINERVA (n. PCs =1)\"]# [\"5-mer\",\"6-mer\",\"7-mer\"]#\n",
    "alternate_color = False\n",
    "simple_minerva_label = True\n",
    "\n",
    "\n",
    "key =\"AGP_BMI\"\n",
    "subfile = \"\"\n",
    "select_columns_bool = False\n",
    "shortened_shortened = False\n",
    "trans_vec = False\n",
    "add_linmodel_type = False\n",
    "\n",
    "if key == \"Hispanic_BMI\":\n",
    "    numPc = [0,0,0,0,2]#,11,12,13,14,15,16,17,18,19,20] \n",
    "    phen = [\"bmi_v2\" for i in range(len(numPc))]#\" #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"body mass index (BMI)\" #\"antibiotic history\" #\"colorectal cancer status\"#\"bmi\"#\"bmi\"#\"antibiotic history\" #\"colorectal cancer status\"#\"Preterm Birth\"#\"\n",
    "    phen_type = \"cont\" \n",
    "    \n",
    "    folder_names = [\"Hispanic_k6\" for i in range(len(numPc))]\n",
    "    file_names = ['rawfilter_TRUE','bmcfilter_TRUE','ComBatfilter_TRUE','limmafilter_TRUE','minerva_first2filter_TRUE'] \n",
    "    select_columns_bool = True\n",
    "    select_labels = [\"Raw\",\"BMC\",\"ComBat\",\"limma\",\"MINERVA (n. PCs =2)\"] #\"Refactor (n. PCs =9)\",\"SmartSVA (n. PCs =3)\",\n",
    "    metric_word = \"pearson\"\n",
    "    chosen_classifier = \"Naive Bayes\"\n",
    "    title = 'Pearson for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "    pair_test_all = True\n",
    "    trans = \"clr_scale\"\n",
    "    limit_spec =(-0.1,0.25)\n",
    "    shortened=True\n",
    "    not_rotate=False\n",
    "    \n",
    "    subfile = \"\"\n",
    "\n",
    "\n",
    "if key == \"Hispanic_BMI_calibrate\":\n",
    "    numPc = [0,1,2,3,4,5,6,7,8,9,10,11]#,11,12,13,14,15,16,17,18,19,20] \n",
    "    phen = [\"bmi_v2\" for i in range(len(numPc))]#\" #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"body mass index (BMI)\" #\"antibiotic history\" #\"colorectal cancer status\"#\"bmi\"#\"bmi\"#\"antibiotic history\" #\"colorectal cancer status\"#\"Preterm Birth\"#\"\n",
    "    phen_type = \"cont\" \n",
    "    \n",
    "    folder_names = [\"Hispanic_k7\" for i in range(len(numPc))]\n",
    "    file_names =['rawfilter_TRUE']+['minerva_first' + str(numPc[i]) + 'filter_TRUE' for i in range(1,len(numPc))]\n",
    "    select_columns_bool = True\n",
    "    select_labels = numPc#[\"Raw\"] + [\"MINERVA\" + str(i) for i in range(1,len(numPc))] \n",
    "    metric_word = \"pearson\"\n",
    "    chosen_classifier = \"Naive Bayes\"\n",
    "    title = 'Pearson for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "    pair_test_all = False\n",
    "    trans = \"clr_scale\"\n",
    "    limit_spec =(-0.1,0.25)\n",
    "    shortened=True\n",
    "    not_rotate=True\n",
    "    add_linmodel_type  = True\n",
    "    \n",
    "    subfile = \"\"\n",
    "    \n",
    "if key == \"Hispanic_abx\":\n",
    "    numPc = [0,0,0,0,11]#,11,12,13,14,15,16,17,18,19,20] \n",
    "    phen = [\"antibiotic\" for i in range(len(numPc))]#\" #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"antibiotic history\" \n",
    "    phen_type = \"class\" \n",
    "    \n",
    "    folder_names = [\"Hispanic_k7\" for i in range(len(numPc))]\n",
    "    file_names = ['rawfilter_TRUE','bmcfilter_TRUE','ComBatfilter_TRUE','limmafilter_TRUE','minerva_first11filter_TRUE'] \n",
    "    select_columns_bool = True\n",
    "    if simple_minerva_label:\n",
    "        select_labels = [\"Raw\",\"BMC\",\"ComBat\",\"limma\",\"MINERVA\"] #\"Refactor (n. PCs =9)\",\"SmartSVA (n. PCs =3)\",\n",
    "   \n",
    "    else:\n",
    "        select_labels = [\"Raw\",\"BMC\",\"ComBat\",\"limma\",\"MINERVA (n. PCs =11)\"] #\"Refactor (n. PCs =9)\",\"SmartSVA (n. PCs =3)\",\n",
    "    metric_word = \"auc_all\"\n",
    "    chosen_classifier = \"Naive Bayes\"\n",
    "    title = 'AUC for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "    pair_test_all = True\n",
    "    trans = \"clr_scale\"\n",
    "    limit_spec =(0.45,0.8)\n",
    "    shortened=True\n",
    "    not_rotate=False\n",
    "    subfile = \"\"\n",
    "if key == \"Hispanic_abx_calibrate\":\n",
    "    numPc = [0,1,2,3,4,5,6,7,8,9,10,11,12,14] \n",
    "    phen = [\"antibiotic\" for i in range(len(numPc))]#\" #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"antibiotic history\" \n",
    "    phen_type = \"class\" \n",
    "    \n",
    "    folder_names = [\"Hispanic_k7\" for i in range(len(numPc))]\n",
    "    file_names =['rawfilter_TRUE']+['minerva_first' + str(numPc[i]) + 'filter_TRUE' for i in range(1,len(numPc))]\n",
    "    select_columns_bool = True\n",
    "    #select_labels = [\"Raw\"] + [\"MINERVA\" + str(i) for i in range(1,len(numPc))] \n",
    "    select_labels = numPc\n",
    "    metric_word = \"auc_all\"\n",
    "    chosen_classifier = \"Naive Bayes\"\n",
    "    title = 'AUC for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "    pair_test_all = False\n",
    "    trans = \"clr_scale\"  \n",
    "    limit_spec =(0.45,0.80)\n",
    "    not_rotate=True\n",
    "    subfile = \"\"\n",
    "    \n",
    "if key == \"Wirbel_PhenoCorrect\":\n",
    "    phen = [\"DiseaseState\",\"DiseaseState\"]#\" #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"colorectal cancer status\" #\"antibiotic history\" #\"colorectal cancer status\"#\"bmi\"#\"bmi\"#\"antibiotic history\" #\"colorectal cancer status\"#\"Preterm Birth\"#\"\n",
    "    phen_type = \"class\"\n",
    "    metric_word = 'accuracy'\n",
    "    \n",
    "    numPc = [0,0] \n",
    "    folder_names = [\"CRC_wirbel_otu\",\"CRC_wirbel_otu_PhenoCorrect\"]\n",
    "    file_names = ['rawfilter_TRUE','PhenoCorrectfilter_TRUE']\n",
    "    select_columns_bool = True\n",
    "    select_labels = [\"Raw\",\"PhenoCorrect\"]#[0,1,2,3,4,5,6,7,8,9,10]#[\"raw\",\"BMC\",\"ComBat\",\"limma\",\"SmartSVA (n. PCs =5)\",\"MINERVA (n. PCs =5)\"]#[0,1,2,3,4,5,6,7,8,9,10]#\n",
    "    title = 'AUC for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "\n",
    "    chosen_classifier = \"Random Forest\"\n",
    "    title = 'Accuracy for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "    pair_test_all = False\n",
    "    trans = \"clr_scale\"\n",
    "    \n",
    "if key == \"Wirbel_DataAugmentation\":\n",
    "    phen = [\"DiseaseState\",\"DiseaseState\"]#\" #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"colorectal cancer status\" #\"antibiotic history\" #\"colorectal cancer status\"#\"bmi\"#\"bmi\"#\"antibiotic history\" #\"colorectal cancer status\"#\"Preterm Birth\"#\"\n",
    "    phen_type = \"class\"\n",
    "    metric_word = 'accuracy'\n",
    "    \n",
    "    numPc = [0,0] \n",
    "    folder_names = [\"CRC_wirbel_otu\",\"CRC_wirbel_otu_DataAugmentation\"]\n",
    "    file_names = ['rawfilter_TRUE','DataAugmentationfilter_TRUE']\n",
    "    select_columns_bool = True\n",
    "    select_labels = [\"Raw\",\"DataAugmentation\"]#[0,1,2,3,4,5,6,7,8,9,10]#[\"raw\",\"BMC\",\"ComBat\",\"limma\",\"SmartSVA (n. PCs =5)\",\"MINERVA (n. PCs =5)\"]#[0,1,2,3,4,5,6,7,8,9,10]#\n",
    "    title = 'AUC for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "\n",
    "    chosen_classifier = \"Random Forest\"\n",
    "    title = 'Accuracy for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "    pair_test_all = False\n",
    "    trans = \"clr_scale\"\n",
    "\n",
    "if key == \"Thomas_kmer_PredDomainPheno\":\n",
    "    \n",
    "    phen = [\"bin_crc_adenomaORnormal\",\"domain_pheno\"]#\" #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"colorectal cancer status\" #\"antibiotic history\" #\"colorectal cancer status\"#\"bmi\"#\"bmi\"#\"antibiotic history\" #\"colorectal cancer status\"#\"Preterm Birth\"#\"\n",
    "    phen_type = \"class\"\n",
    "    \n",
    "    numPc = [0,0] \n",
    "    folder_names = [\"Thomas_k6\",\"Thomas_k6_PredDomainPheno\"]\n",
    "    file_names = ['rawfilter_TRUE','PredDomainPhenofilter_TRUE']\n",
    "    select_columns_bool = True\n",
    "    select_labels = [\"Raw\",\"PredDomainPheno\"]#[0,1,2,3,4,5,6,7,8,9,10]#[\"raw\",\"BMC\",\"ComBat\",\"limma\",\"SmartSVA (n. PCs =5)\",\"MINERVA (n. PCs =5)\"]#[0,1,2,3,4,5,6,7,8,9,10]#\n",
    "    metric_word = \"accuracy\"\n",
    "    chosen_classifier = \"Random Forest\"\n",
    "    title = 'Accuracy for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "    pair_test_all = False\n",
    "    trans = \"clr_scale\"\n",
    "    \n",
    "if key == \"Thomas_kmer_PhenoCorrect_multi\":\n",
    "    phen = [\"bin_crc_adenomaORnormal\",\"bin_crc_adenomaORnormal\"]#\" #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"colorectal cancer status\" #\"antibiotic history\" #\"colorectal cancer status\"#\"bmi\"#\"bmi\"#\"antibiotic history\" #\"colorectal cancer status\"#\"Preterm Birth\"#\"\n",
    "    phen_type = \"class\"\n",
    "    \n",
    "    numPc = [0,0] \n",
    "    folder_names = [\"Thomas_k6\",\"Thomas_k6_PhenoCorrect\"]\n",
    "    file_names = ['rawfilter_TRUE','PhenoCorrectfilter_TRUE']\n",
    "    select_columns_bool = True\n",
    "    select_labels = [\"Raw\",\"PhenoCorrect\"]#[0,1,2,3,4,5,6,7,8,9,10]#[\"raw\",\"BMC\",\"ComBat\",\"limma\",\"SmartSVA (n. PCs =5)\",\"MINERVA (n. PCs =5)\"]#[0,1,2,3,4,5,6,7,8,9,10]#\n",
    "    metric_word = \"accuracy\"\n",
    "    chosen_classifier = \"Naive Bayes\"\n",
    "    title = 'Accuracy for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "    pair_test_all = False\n",
    "    trans = \"clr_scale\"\n",
    "\n",
    "if key == \"Thomas_kmer_DataAugment\":\n",
    "    phen = [\"bin_crc_adenomaORnormal\",\"bin_crc_adenomaORnormal\"]#\" #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"colorectal cancer status\" #\"antibiotic history\" #\"colorectal cancer status\"#\"bmi\"#\"bmi\"#\"antibiotic history\" #\"colorectal cancer status\"#\"Preterm Birth\"#\"\n",
    "    phen_type = \"class\"\n",
    "    \n",
    "    numPc = [0,0] \n",
    "    folder_names = [\"Thomas_k6\",\"Thomas_k6_DataAugmentation\"]\n",
    "    file_names = ['rawfilter_TRUE','DataAugmentationfilter_TRUE']\n",
    "    select_columns_bool = True\n",
    "    select_labels = [\"Raw\",\"DataAugmentation\"]#[0,1,2,3,4,5,6,7,8,9,10]#[\"raw\",\"BMC\",\"ComBat\",\"limma\",\"SmartSVA (n. PCs =5)\",\"MINERVA (n. PCs =5)\"]#[0,1,2,3,4,5,6,7,8,9,10]#\n",
    "    metric_word = \"accuracy\"\n",
    "    chosen_classifier = \"Random Forest\"\n",
    "    title = 'Accuracy for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "    pair_test_all = False\n",
    "    trans = \"clr_scale\"\n",
    "    \n",
    "if key == \"AGP_abx_time_lapse\":\n",
    "    kmer_spec = 7\n",
    "    numPc = [0,0] \n",
    "    phen = [\"Abx0_6\",\"Abx6_12\"]#\" #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"antibiotic history at 0-6 mo, 6-12 mo\"\n",
    "    phen_type = \"class\" \n",
    "    \n",
    "    folder_names = [\"AGP_max_k\" + str(kmer_spec) + \"_Abx0_6\",\"AGP_max_k\" + str(kmer_spec) + \"_Abx6_12\",]\n",
    "    file_names =['rawfilter_TRUE' for i in range(0,len(numPc))]\n",
    "    select_columns_bool = True\n",
    "    #select_labels = [\"Raw\"] + [\"MINERVA\" + str(i) for i in range(1,len(numPc))] \n",
    "    select_labels = ['Abx 0-6 months','Abx 6-12 months']\n",
    "    metric_word = \"auc_all\"\n",
    "    chosen_classifier = \"Random Forest\"\n",
    "    title = 'AUC for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "    pair_test_all = False\n",
    "    trans = \"clr_scale\"  \n",
    "    limit_spec =(0.6,0.73)\n",
    "    not_rotate=True\n",
    "    subfile = \"\"\n",
    "\n",
    "if key == \"AGP_abx6_12_calibrate\":\n",
    "    kmer_spec = 5\n",
    "    abx_spec = \"6_12\"\n",
    "    numPc = [0,1,2,3,4,5,6,7,8,9,10] \n",
    "    phen = [\"Abx\" + abx_spec for i in range(len(numPc))]#\" #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"antibiotic history\" + abx_spec \n",
    "    phen_type = \"class\" \n",
    "    \n",
    "    folder_names = [\"AGP_max_k\" + str(kmer_spec) + \"_Abx\" + abx_spec for i in range(len(numPc))]\n",
    "    file_names =['rawfilter_TRUE']+['minerva_first' + str(numPc[i]) + 'filter_TRUE' for i in range(1,len(numPc))]\n",
    "    select_columns_bool = True\n",
    "    #select_labels = [\"Raw\"] + [\"MINERVA\" + str(i) for i in range(1,len(numPc))] \n",
    "    select_labels = numPc\n",
    "    metric_word = \"auc_all\"\n",
    "    chosen_classifier = \"Random Forest\"\n",
    "    title = 'AUC for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "    pair_test_all = False\n",
    "    trans = \"clr_scale\"  \n",
    "    limit_spec =(0.55,0.70)\n",
    "    not_rotate=True\n",
    "    subfile = \"\"\n",
    "if key == \"AGP_abx_calibrate\":\n",
    "    numPc = [0,1,2,3,4,5,6,7,8,9,10] \n",
    "    phen = [\"bin_antibiotic_last_year\" for i in range(len(numPc))]#\" #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"antibiotic history\" \n",
    "    phen_type = \"class\" \n",
    "    \n",
    "    folder_names = [\"AGP_max_k6\" for i in range(len(numPc))]\n",
    "    file_names =['rawfilter_TRUE']+['minerva_first' + str(numPc[i]) + 'filter_TRUE' for i in range(1,len(numPc))]\n",
    "    select_columns_bool = True\n",
    "    #select_labels = [\"Raw\"] + [\"MINERVA\" + str(i) for i in range(1,len(numPc))] \n",
    "    select_labels = numPc\n",
    "    metric_word = \"auc_all\"\n",
    "    chosen_classifier = \"Random Forest\"\n",
    "    title = 'AUC for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "    pair_test_all = False\n",
    "    trans = \"clr_scale\"  \n",
    "    limit_spec =(0.55,0.70)\n",
    "    not_rotate=True\n",
    "    subfile = \"class_pred/\"\n",
    "    \n",
    "\n",
    "if key == \"AGP_abx\":\n",
    "    numPc = [0,0,0,0,2]#,11,12,13,14,15,16,17,18,19,20] \n",
    "    phen = [\"bin_antibiotic_last_year\" for i in range(len(numPc))]#\" #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"antibiotic history\" \n",
    "    phen_type = \"class\" \n",
    "    \n",
    "    folder_names = [\"AGP_max_k6\" for i in range(len(numPc))]\n",
    "    file_names = ['rawfilter_TRUE','bmcfilter_TRUE','ComBatfilter_TRUE','limmafilter_TRUE','minerva_first2filter_TRUE'] \n",
    "    select_columns_bool = True\n",
    "    select_labels = [\"Raw\",\"BMC\",\"ComBat\",\"limma\",\"MINERVA (n. PCs =2)\"] #\"Refactor (n. PCs =9)\",\"SmartSVA (n. PCs =3)\",\n",
    "    metric_word = \"auc_all\"\n",
    "    chosen_classifier = \"Naive Bayes\"\n",
    "    title = 'AUC for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "    pair_test_all = True\n",
    "    trans = \"clr_scale\"\n",
    "    limit_spec =(0.55,0.68)\n",
    "    shortened=True\n",
    "    not_rotate=False\n",
    "    subfile = \"class_pred/\"\n",
    "if key == \"AGP_BMI_calibrate\":\n",
    "    numPc = [0,1,2,3,4,5,6,7,8,9,10]#,11,12,13,14,15,16,17,18,19,20] \n",
    "    phen = [\"bmi_corrected\" for i in range(len(numPc))]#\" #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"body mass index (BMI)\" #\"antibiotic history\" #\"colorectal cancer status\"#\"bmi\"#\"bmi\"#\"antibiotic history\" #\"colorectal cancer status\"#\"Preterm Birth\"#\"\n",
    "    phen_type = \"cont\" \n",
    "    \n",
    "    folder_names = [\"AGP_max_k6\" for i in range(len(numPc))]\n",
    "    file_names =['rawfilter_TRUE']+['minerva_first' + str(numPc[i]) + 'filter_TRUE' for i in range(1,len(numPc))]\n",
    "    select_columns_bool = True\n",
    "    select_labels = numPc#[\"Raw\"] + [\"MINERVA\" + str(i) for i in range(1,len(numPc))] \n",
    "    metric_word = \"pearson\"\n",
    "    chosen_classifier = \"Naive Bayes\"\n",
    "    title = 'Pearson for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "    pair_test_all = False\n",
    "    trans = \"clr_scale\"\n",
    "    limit_spec =(0.13,0.33)\n",
    "    shortened=True\n",
    "    not_rotate=True\n",
    "    \n",
    "    subfile = \"cont_pred/\"\n",
    "    \n",
    "if key == \"AGP_BMI\":\n",
    "    numPc = [0,0,0,0,2]#,11,12,13,14,15,16,17,18,19,20] \n",
    "    phen = [\"bmi_corrected\" for i in range(len(numPc))]#\" #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"body mass index (BMI)\" #\"antibiotic history\" #\"colorectal cancer status\"#\"bmi\"#\"bmi\"#\"antibiotic history\" #\"colorectal cancer status\"#\"Preterm Birth\"#\"\n",
    "    phen_type = \"cont\" \n",
    "    \n",
    "    folder_names = [\"AGP_max_k6\" for i in range(len(numPc))]\n",
    "    file_names = ['rawfilter_TRUE','bmcfilter_TRUE','ComBatfilter_TRUE','limmafilter_TRUE','minerva_first2filter_TRUE'] \n",
    "    select_columns_bool = True\n",
    "    if simple_minerva_label:\n",
    "        select_labels = [\"Raw\",\"BMC\",\"ComBat\",\"limma\",\"MINERVA\"] #\"Refactor (n. PCs =9)\",\"SmartSVA (n. PCs =3)\",\n",
    "   \n",
    "    else:\n",
    "        select_labels = [\"Raw\",\"BMC\",\"ComBat\",\"limma\",\"MINERVA (n. PCs =2)\"] #\"Refactor (n. PCs =9)\",\"SmartSVA (n. PCs =3)\",\n",
    "    metric_word = \"pearson\"\n",
    "    chosen_classifier = \"Naive Bayes\"\n",
    "    title = 'Pearson for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "    pair_test_all = True\n",
    "    trans = \"clr_scale\"\n",
    "    limit_spec =(0.13,0.37)\n",
    "    shortened=True\n",
    "    not_rotate=False\n",
    "    \n",
    "    subfile = \"cont_pred/\"\n",
    "\n",
    "if key == \"Thomas_kmer\":\n",
    "    numPc = [0,0,0,0,4] \n",
    "    phen = [\"bin_crc_adenomaORnormal\" for i in range(len(numPc))]#\" #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"colorectal cancer status\" #\"antibiotic history\" #\"colorectal cancer status\"#\"bmi\"#\"bmi\"#\"antibiotic history\" #\"colorectal cancer status\"#\"Preterm Birth\"#\"\n",
    "    phen_type = \"class\"\n",
    "    \n",
    "    \n",
    "    folder_names = [\"Thomas_k6\" for i in range(len(numPc))]\n",
    "    file_names = ['rawfilter_TRUE','bmcfilter_TRUE','ComBatfilter_TRUE','limmafilter_TRUE','minerva_first4filter_TRUE'] \n",
    "    select_columns_bool = True\n",
    "    if simple_minerva_label:\n",
    "        select_labels = [\"Raw\",\"BMC\",\"ComBat\",\"limma\",\"MINERVA\"] #\"Refactor (n. PCs =9)\",\"SmartSVA (n. PCs =3)\",\n",
    "   \n",
    "    else:\n",
    "        select_labels = [\"Raw\",\"BMC\",\"ComBat\",\"limma\",\"MINERVA (n. PCs =4)\"]\n",
    "    metric_word = \"auc_all\"\n",
    "    chosen_classifier = \"Naive Bayes\"\n",
    "    title = 'AUC for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "    pair_test_all = True\n",
    "    limit_spec =(0.5,0.85)\n",
    "    shortened=True\n",
    "    not_rotate=False\n",
    "if key == \"Thomas_kmer_none_clr\":\n",
    "    numPc = [0,5,0,4] \n",
    "    phen = [\"bin_crc_adenomaORnormal\" for i in range(len(numPc))]#\" #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"colorectal cancer status\" #\"antibiotic history\" #\"colorectal cancer status\"#\"bmi\"#\"bmi\"#\"antibiotic history\" #\"colorectal cancer status\"#\"Preterm Birth\"#\"\n",
    "    phen_type = \"class\"\n",
    "    \n",
    "    \n",
    "    folder_names = [\"Thomas_k6\" for i in range(len(numPc))]\n",
    "    file_names = ['rawfilter_TRUE','rawfilter_TRUE','minerva_first5filter_TRUE','minerva_first4filter_TRUE'] \n",
    "    select_columns_bool = True\n",
    "    select_labels = [\"Raw no trans\",\"Raw clr+scale\",\"MINERVA no trans (n. PCs =5)\",\"MINERVA clr+scale (n. PCs =4)\"]\n",
    "    metric_word = \"auc_all\"\n",
    "    chosen_classifier = \"Naive Bayes\"\n",
    "    title = 'AUC for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "    pair_test_all = True\n",
    "    limit_spec =(0.5,1)\n",
    "    shortened=True\n",
    "    not_rotate=False\n",
    "    shortened_shortened = True\n",
    "    alternate_color = True\n",
    "     \n",
    "    trans = [\"none\",\"clr_scale\",\"none\",\"clr_scale\"]\n",
    "    trans_vec = True\n",
    "if key == \"Thomas_kmer_none_calibrate\":\n",
    "    numPc = [0,1,2,3,4,5,6,7] \n",
    "    phen = [\"bin_crc_adenomaORnormal\" for i in range(len(numPc))]#\"bin_crc_adenomaORnormal\" #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"colorectal cancer status\" #\"antibiotic history\" #\"colorectal cancer status\"#\"bmi\"#\"bmi\"#\"antibiotic history\" #\"colorectal cancer status\"#\"Preterm Birth\"#\"\n",
    "    phen_type = \"class\"\n",
    "    \n",
    "    \n",
    "    folder_names = [\"Thomas_k6\" for i in range(len(numPc))]\n",
    "    file_names =['rawfilter_TRUE']+['minerva_first' + str(numPc[i]) + 'filter_TRUE' for i in range(1,len(numPc))]\n",
    "    select_columns_bool = True\n",
    "    select_labels = numPc \n",
    "    metric_word = \"auc_all\"\n",
    "    chosen_classifier = \"Naive Bayes\"\n",
    "    title = 'AUC for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "    pair_test_all = False\n",
    "    limit_spec =(0.5,0.85)\n",
    "    shortened=True\n",
    "    not_rotate=True\n",
    "    trans_vec = True\n",
    "    trans = [\"none\" for i in range(len(numPc))]\n",
    "\n",
    "if key == \"Thomas_kmer_calibrate\":\n",
    "    numPc = [0,1,2,3,4,5,6,7,8,9,10] \n",
    "    phen = [\"bin_crc_adenomaORnormal\" for i in range(len(numPc))]#\"bin_crc_adenomaORnormal\" #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"colorectal cancer status\" #\"antibiotic history\" #\"colorectal cancer status\"#\"bmi\"#\"bmi\"#\"antibiotic history\" #\"colorectal cancer status\"#\"Preterm Birth\"#\"\n",
    "    phen_type = \"class\"\n",
    "    \n",
    "    \n",
    "    folder_names = [\"Thomas_k6\" for i in range(len(numPc))]\n",
    "    file_names =['rawfilter_TRUE']+['minerva_first' + str(numPc[i]) + 'filter_TRUE' for i in range(1,len(numPc))]\n",
    "    select_columns_bool = True\n",
    "    select_labels = numPc \n",
    "    metric_word = \"auc_all\"\n",
    "    chosen_classifier = \"Naive Bayes\"\n",
    "    title = 'AUC for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "    pair_test_all = False\n",
    "    limit_spec =(0.5,0.85)\n",
    "    shortened=True\n",
    "    not_rotate=True\n",
    "\n",
    "    \n",
    "if key == \"Thomas_Augmentation\":\n",
    "    numPc = [0,0]\n",
    "    phen = \"bin_crc_normal\"# #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_crc_adenomaORnormal\"#\"\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"colorectal cancer status\" #\"antibiotic history\" #\"colorectal cancer status\"#\"bmi\"#\"bmi\"#\"antibiotic history\" #\"colorectal cancer status\"#\"Preterm Birth\"#\"\n",
    "    phen_type = \"class\"#\"class\n",
    "    folder_names = ['CRC_thomas_otu', 'CRC_thomas_otu_DataAugmentation']\n",
    "    file_names = ['rawfilter_TRUE','DataAugmentationfilter_TRUE']\n",
    "    \n",
    "    \n",
    "if key == \"Thomas_otu_calibrate\":    \n",
    "    \n",
    "    numPc = [0,1,2,3,4,5,6,7,8,9,10] \n",
    "    phen = [\"bin_crc_normal\" for i in range(len(numPc))]#\" #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"colorectal cancer status\" #\"antibiotic history\" #\"colorectal cancer status\"#\"bmi\"#\"bmi\"#\"antibiotic history\" #\"colorectal cancer status\"#\"Preterm Birth\"#\"\n",
    "    phen_type = \"class\"\n",
    "    folder_names = [\"CRC_thomas_otu\" for i in range(len(numPc))]\n",
    "    file_names =['rawfilter_TRUE']+['minerva_first' + str(numPc[i]) + 'filter_TRUE' for i in range(1,len(numPc))]\n",
    "    select_columns_bool = True\n",
    "    select_labels = numPc\n",
    "    metric_word = \"auc_all\"\n",
    "    chosen_classifier = \"Naive Bayes\"\n",
    "    title = 'AUC for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "    pair_test_all = True\n",
    "    limit_spec =(0.5,1)\n",
    "    shortened=True\n",
    "    not_rotate=False\n",
    "    \n",
    "    \n",
    "if key == \"Thomas_otu\":   \n",
    "    numPc = [0,0,0,0,4] \n",
    "    phen = [\"bin_crc_adenomaORnormal\" for i in range(len(numPc))]#\" #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"colorectal cancer status\" #\"antibiotic history\" #\"colorectal cancer status\"#\"bmi\"#\"bmi\"#\"antibiotic history\" #\"colorectal cancer status\"#\"Preterm Birth\"#\"\n",
    "    phen_type = \"class\"\n",
    "    \n",
    "    folder_names = [\"CRC_Thomas_otu\" for i in range(len(numPc))]\n",
    "    file_names = ['rawfilter_TRUE','bmcfilter_TRUE','ComBatfilter_TRUE','limmafilter_TRUE','minerva_first4filter_TRUE'] \n",
    "    select_columns_bool = True\n",
    "    select_labels = [\"Raw\",\"BMC\",\"ComBat\",\"limma\",\"MINERVA (n. PCs =4)\"]\n",
    "    metric_word = \"auc_all\"\n",
    "    chosen_classifier = \"Naive Bayes\"\n",
    "    title = 'AUC for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "    pair_test_all = True\n",
    "    limit_spec =(0.5,1)\n",
    "    shortened=True\n",
    "    not_rotate=False\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "if key == \"Thomas_mse\":\n",
    "    numPc = [0,0]\n",
    "    phen = \"bin_crc_normal\"# #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_crc_adenomaORnormal\"#\"\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"colorectal cancer status\" #\"antibiotic history\" #\"colorectal cancer status\"#\"bmi\"#\"bmi\"#\"antibiotic history\" #\"colorectal cancer status\"#\"Preterm Birth\"#\"\n",
    "    phen_type = \"cont\"#\"class\"\n",
    "    folder_names = ['CRC_thomas_otu', 'CRC_thomas_otu_PhenCorrect']\n",
    "    file_names = ['rawfilter_TRUE','DataAugmentationfilter_TRUE']\n",
    "\n",
    "if key == \"Gibbons_k_otu\":\n",
    "    numPc = [0,0,150,4]#,11,12,13,14,15,16,17,18,19,20] \n",
    "    phen = [\"bin_crc\",\"bin_crc_normal\",\"bin_crc\",\"bin_crc_normal\" ]#\" #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"colorectal cancer status (normal vs cancer)\" #\"antibiotic history\" #\"colorectal cancer status\"#\"bmi\"#\"bmi\"#\"antibiotic history\" #\"colorectal cancer status\"#\"Preterm Birth\"#\"\n",
    "    \n",
    "    phen_type = \"class\"\n",
    "    \n",
    "    folder_names = [\"CRC_otu\",\"CRC_k7\",\"CRC_otu\",\"CRC_k7\"]\n",
    "    file_names = ['rawfilter_TRUE','rawfilter_TRUE','minerva_first150filter_TRUE','minerva_first4filter_TRUE'] \n",
    "    select_columns_bool = True\n",
    "    select_labels = [\"Raw OTU\",\"Raw 7-mer\",\"MINERVA OTU (n. PCs =150)\",\"MINERVA 7-mer (n. PCs =4)\"] #\"Refactor (n. PCs =9)\",\"SmartSVA (n. PCs =3)\",\n",
    "    metric_word = \"auc_all\"\n",
    "    chosen_classifier = \"Naive Bayes\"\n",
    "    title = 'AUC for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "    pair_test_all = True\n",
    "    trans = \"clr_scale\"\n",
    "    limit_spec =(0.4,1.1)\n",
    "    shortened=True\n",
    "    shortened_shortened=True\n",
    "    not_rotate=False\n",
    "    alternate_color = True\n",
    "    \n",
    "if key == \"Gibbons_calibrate_otu\":\n",
    "    numPc = [0,1,2,3,10,20,40,60,80,100,140,150,200,220,240,260,300]\n",
    "    phen = [\"bin_crc\"  for i in range(len(numPc))]#\" #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"colorectal cancer status (normal vs cancer)\" #\"antibiotic history\" #\"colorectal cancer status\"#\"bmi\"#\"bmi\"#\"antibiotic history\" #\"colorectal cancer status\"#\"Preterm Birth\"#\"\n",
    "    \n",
    "    phen_type = \"class\"\n",
    "    \n",
    "    \n",
    "    folder_names = [\"CRC_otu\" for i in range(len(numPc))]\n",
    "    file_names =['rawfilter_TRUE']+['minerva_first' + str(numPc[i]) + 'filter_TRUE' for i in range(1,len(numPc))]\n",
    "    select_columns_bool = True\n",
    "    #select_labels = [\"Raw\"] + [\"MINERVA\" + str(i) for i in range(1,len(numPc))] \n",
    "    select_labels = numPc\n",
    "    metric_word = \"auc_all\"\n",
    "    chosen_classifier = \"Naive Bayes\"\n",
    "    title = 'AUC for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "    pair_test_all = False\n",
    "    trans = \"clr_scale\"  \n",
    "    limit_spec =(0.4,1)\n",
    "    not_rotate=True\n",
    "    subfile = \"class_pred/\"\n",
    "if key == \"Gibbons_calibrate\":\n",
    "    numPc = [0,1,2,3,4,5,6,7,8,9,10] \n",
    "    phen = [\"bin_crc_adenomaORnormal\"  for i in range(len(numPc))]#\" #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"colorectal cancer status (adenoma/normal vs cancer)\" #\"antibiotic history\" #\"colorectal cancer status\"#\"bmi\"#\"bmi\"#\"antibiotic history\" #\"colorectal cancer status\"#\"Preterm Birth\"#\"\n",
    "    \n",
    "    phen_type = \"class\"\n",
    "    \n",
    "    \n",
    "    folder_names = [\"CRC_k7\" for i in range(len(numPc))]\n",
    "    file_names =['rawfilter_TRUE']+['minerva_first' + str(numPc[i]) + 'filter_TRUE' for i in range(1,len(numPc))]\n",
    "    select_columns_bool = True\n",
    "    #select_labels = [\"Raw\"] + [\"MINERVA\" + str(i) for i in range(1,len(numPc))] \n",
    "    select_labels = numPc\n",
    "    metric_word = \"auc_all\"\n",
    "    chosen_classifier = \"Naive Bayes\"\n",
    "    title = 'AUC for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "    pair_test_all = False\n",
    "    trans = \"clr_scale\"  \n",
    "    limit_spec =(0.4,1)\n",
    "    not_rotate=True\n",
    "    \n",
    "    \n",
    "if key == \"Gibbons\":\n",
    "    numPc = [0,0,0,0,10] \n",
    "    phen = [\"bin_crc_adenomaORnormal\"  for i in range(len(numPc))]#\" #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"colorectal cancer status\" #\"antibiotic history\" #\"colorectal cancer status\"#\"bmi\"#\"bmi\"#\"antibiotic history\" #\"colorectal cancer status\"#\"Preterm Birth\"#\"\n",
    "    phen_type = \"class\"\n",
    "    \n",
    "    \n",
    "    folder_names = [\"CRC_k7\" for i in range(len(numPc))]\n",
    "    \n",
    "    file_names = ['rawfilter_TRUE','bmcfilter_TRUE','ComBatfilter_TRUE','limmafilter_TRUE',\n",
    "             'minerva_first10filter_TRUE']   #['smartsva_first10' + str(numPc[i]) + 'filter_TRUE' for i in range(len(numPc))]\n",
    "    select_columns_bool = True\n",
    "    \n",
    "    if simple_minerva_label:\n",
    "        select_labels = [\"Raw\",\"BMC\",\"ComBat\",\"limma\",\"MINERVA\"] #\"Refactor (n. PCs =9)\",\"SmartSVA (n. PCs =3)\",\n",
    "   \n",
    "    else:\n",
    "        select_labels = [\"Raw\",\"BMC\",\"ComBat\",\"limma\",\"MINERVA (n. PCs =10)\"]#[0,1,2,3,4,5,6,7,8,9,10]#[\"raw\",\"BMC\",\"ComBat\",\"limma\",\"SmartSVA (n. PCs =5)\",\"MINERVA (n. PCs =5)\"]#[0,1,2,3,4,5,6,7,8,9,10]#\n",
    "    \n",
    "   \n",
    "    metric_word = \"auc_all\"\n",
    "    chosen_classifier = \"Naive Bayes\"\n",
    "    title = 'AUC for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "    pair_test_all = True\n",
    "    limit_spec =(0.4,1)\n",
    "    shortened=True\n",
    "    not_rotate=False\n",
    "\n",
    "    \n",
    "if key == \"Gibbons_DataAugment\":\n",
    "    phen = [\"bin_crc_adenomaORnormal\",\"bin_crc_adenomaORnormal\"]#\" #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"colorectal cancer status\" #\"antibiotic history\" #\"colorectal cancer status\"#\"bmi\"#\"bmi\"#\"antibiotic history\" #\"colorectal cancer status\"#\"Preterm Birth\"#\"\n",
    "    phen_type = \"class\"\n",
    "    \n",
    "    numPc = [0,0] \n",
    "    folder_names = [\"CRC_k7\",\"CRC_k7_DataAugmentation\"]\n",
    "    file_names = ['rawfilter_TRUE','DataAugmentationfilter_TRUE']\n",
    "    select_columns_bool = True\n",
    "    metric_word = \"accuracy\"\n",
    "    select_labels = [\"Raw\",\"DataAugmentation\"]#[0,1,2,3,4,5,6,7,8,9,10]#[\"raw\",\"BMC\",\"ComBat\",\"limma\",\"SmartSVA (n. PCs =5)\",\"MINERVA (n. PCs =5)\"]#[0,1,2,3,4,5,6,7,8,9,10]#\n",
    "    chosen_classifier = \"Random Forest\"\n",
    "    title = 'Accuracy for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "    pair_test_all = False\n",
    "    trans = \"clr_scale\"\n",
    "    \n",
    "if key == \"Gibbons_PhenoCorrect_multi\":\n",
    "    phen = [\"bin_crc_adenomaORnormal\",\"bin_crc_adenomaORnormal\"]#\" #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"colorectal cancer status\" #\"antibiotic history\" #\"colorectal cancer status\"#\"bmi\"#\"bmi\"#\"antibiotic history\" #\"colorectal cancer status\"#\"Preterm Birth\"#\"\n",
    "    phen_type = \"class\"\n",
    "    \n",
    "    numPc = [0,0] \n",
    "    folder_names = [\"CRC_k7\",\"CRC_k7_PhenoCorrect\"]\n",
    "    file_names = ['rawfilter_TRUE','PhenoCorrectfilter_TRUE']\n",
    "    select_columns_bool = True\n",
    "    select_labels = [\"Raw\",\"PhenoCorrect\"]#[0,1,2,3,4,5,6,7,8,9,10]#[\"raw\",\"BMC\",\"ComBat\",\"limma\",\"SmartSVA (n. PCs =5)\",\"MINERVA (n. PCs =5)\"]#[0,1,2,3,4,5,6,7,8,9,10]#\n",
    "\n",
    "    metric_word = \"accuracy\"\n",
    "    select_labels = [\"Raw\",\"PhenoCorrection\"]#[0,1,2,3,4,5,6,7,8,9,10]#[\"raw\",\"BMC\",\"ComBat\",\"limma\",\"SmartSVA (n. PCs =5)\",\"MINERVA (n. PCs =5)\"]#[0,1,2,3,4,5,6,7,8,9,10]#\n",
    "    chosen_classifier = \"Random Forest\"\n",
    "    title = 'Accuracy for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "    pair_test_all = False\n",
    "    trans = \"clr_scale\"\n",
    "    \n",
    "\n",
    "if key == \"Gibbons_PredDomainPheno\":\n",
    "    phen = [\"bin_crc_adenomaORnormal\",\"domain_pheno\"]#\" #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"colorectal cancer status\" #\"antibiotic history\" #\"colorectal cancer status\"#\"bmi\"#\"bmi\"#\"antibiotic history\" #\"colorectal cancer status\"#\"Preterm Birth\"#\"\n",
    "    phen_type = \"class\"\n",
    "    metric_word = 'accuracy'\n",
    "    \n",
    "    numPc = [0,0] \n",
    "    folder_names = [\"CRC_k7\",\"CRC_k7_PredDomainPheno\"]\n",
    "    file_names = ['rawfilter_TRUE','PredDomainPhenofilter_TRUE']\n",
    "    select_columns_bool = True\n",
    "    select_labels = [\"Raw\",\"PredDomainPheno\"]#[0,1,2,3,4,5,6,7,8,9,10]#[\"raw\",\"BMC\",\"ComBat\",\"limma\",\"SmartSVA (n. PCs =5)\",\"MINERVA (n. PCs =5)\"]#[0,1,2,3,4,5,6,7,8,9,10]#\n",
    "    title = 'AUC for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "\n",
    "    \n",
    "if key == \"Wirbel_PredDomainPheno\":\n",
    "    phen = [\"DiseaseState\",\"domain_pheno\"]#\" #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"colorectal cancer status\" #\"antibiotic history\" #\"colorectal cancer status\"#\"bmi\"#\"bmi\"#\"antibiotic history\" #\"colorectal cancer status\"#\"Preterm Birth\"#\"\n",
    "    phen_type = \"class\"\n",
    "    metric_word = 'accuracy'\n",
    "    \n",
    "    numPc = [0,0] \n",
    "    folder_names = [\"CRC_wirbel_otu\",\"CRC_wirbel_otu_PredDomainPheno\"]\n",
    "    file_names = ['rawfilter_TRUE','PredDomainPhenofilter_TRUE']\n",
    "    select_columns_bool = True\n",
    "    select_labels = [\"Raw\",\"PredDomainPheno\"]#[0,1,2,3,4,5,6,7,8,9,10]#[\"raw\",\"BMC\",\"ComBat\",\"limma\",\"SmartSVA (n. PCs =5)\",\"MINERVA (n. PCs =5)\"]#[0,1,2,3,4,5,6,7,8,9,10]#\n",
    "    title = 'AUC for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "    \n",
    "if key == \"Gibbons_PhenoCorrect_reg\":\n",
    "    phen = \"bin_crc_adenomaORnormal\"#\" #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"colorectal cancer status\" #\"antibiotic history\" #\"colorectal cancer status\"#\"bmi\"#\"bmi\"#\"antibiotic history\" #\"colorectal cancer status\"#\"Preterm Birth\"#\"\n",
    "    phen_type = \"cont\"\n",
    "    metric_word = 'pearson'\n",
    "    \n",
    "    numPc = [0,0] \n",
    "    folder_names = [\"CRC_k7\",\"CRC_k7_PhenoCorrect\"]\n",
    "    file_names = ['rawfilter_TRUE','PhenoCorrectfilter_TRUE']\n",
    "    select_columns_bool = True\n",
    "    select_labels = [\"Raw\",\"PhenoCorrect\"]#[0,1,2,3,4,5,6,7,8,9,10]#[\"raw\",\"BMC\",\"ComBat\",\"limma\",\"SmartSVA (n. PCs =5)\",\"MINERVA (n. PCs =5)\"]#[0,1,2,3,4,5,6,7,8,9,10]#\n",
    "    title = 'Pearson for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "    \n",
    "    \n",
    "if key == \"Thomas_PhenoCorrect\":\n",
    "    phen = \"bin_crc_adenomaORnormal\"#\" #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"colorectal cancer status\" #\"antibiotic history\" #\"colorectal cancer status\"#\"bmi\"#\"bmi\"#\"antibiotic history\" #\"colorectal cancer status\"#\"Preterm Birth\"#\"\n",
    "    phen_type = \"class\"\n",
    "    \n",
    "    numPc = [0,0] \n",
    "    folder_names = [\"CRC_thomas_otu\",\"CRC_thomas_otu_PhenoCorrect\"]\n",
    "    file_names =['rawfilter_TRUE']+['PhenoCorrectfilter_TRUE']\n",
    "    select_labels = numPc\n",
    "    metric_word =  'auc_all'\n",
    "if key == \"Thomas_DomainCorrect\":\n",
    "    phen = \"bin_crc_adenomaORnormal\"#\" #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"colorectal cancer status\" #\"antibiotic history\" #\"colorectal cancer status\"#\"bmi\"#\"bmi\"#\"antibiotic history\" #\"colorectal cancer status\"#\"Preterm Birth\"#\"\n",
    "    phen_type = \"class\"\n",
    "    \n",
    "    numPc = [0,0] \n",
    "    folder_names = [\"CRC_thomas_otu\" for i in range(len(numPc))]\n",
    "    file_names =['rawfilter_TRUE']+['DomainCorrectfilter_TRUE']\n",
    "    select_labels = file_names\n",
    "    metric_word =  'auc_all'\n",
    "if key == \"T2D\":\n",
    "    numPc = [0,0,0,0,1] \n",
    "    phen = [\"bin_t2d\" for i in range(len(numPc))] #\" #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"diabetes status\" \n",
    "    phen_type = \"class\"\n",
    "    \n",
    "    \n",
    "    folder_names = [\"T2D_k7\" for i in range(len(numPc))]\n",
    "    file_names = ['rawfilter_TRUE','bmcfilter_TRUE','ComBatfilter_TRUE','limmafilter_TRUE'\n",
    "                  ,'minerva_first1filter_TRUE']   #['smartsva_first10' + str(numPc[i]) + 'filter_TRUE' for i in range(len(numPc))]\n",
    "    select_columns_bool = True\n",
    "    if simple_minerva_label:\n",
    "        select_labels = [\"Raw\",\"BMC\",\"ComBat\",\"limma\",\"MINERVA\"] #\"Refactor (n. PCs =9)\",\"SmartSVA (n. PCs =3)\",\n",
    "   \n",
    "    else:\n",
    "        select_labels = [\"Raw\",\"BMC\",\"ComBat\",\"limma\", \"MINERVA (n. PCs =1)\"]\n",
    "    \n",
    "    metric_word =  'auc_all'\n",
    "    title = 'AUC for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "    pair_test_all = True\n",
    "    chosen_classifier = \"Random Forest\"\n",
    "    limit_spec =(0.4,0.85)\n",
    "    not_rotate=False\n",
    "    shortened = True\n",
    "    \n",
    "if key == \"T2D_calibrate\":\n",
    "\n",
    "\n",
    "    numPc = [0,1,2,3,4,5,6,7,8,9,10] \n",
    "    phen = [\"bin_t2d\" for i in range(len(numPc))]#\" #\"bin_antibiotic_last_year\"#\"bin_crc_normal\"#\"bin_antibiotic_last_year\"#\"bin_crc\"#\"preg_outcome_sub\"#\"#\"gest_age_collection_wk\"## \"preg_outcome\"#\"#\"bmi_corrected\"gest_age_delivery_wk\n",
    "    phen_pretty = \"diabetes status\" #\"antibiotic history\" #\"colorectal cancer status\"#\"bmi\"#\"bmi\"#\"antibiotic history\" #\"colorectal cancer status\"#\"Preterm Birth\"#\"\n",
    "    phen_type = \"class\"\n",
    "    \n",
    "    \n",
    "    folder_names = [\"T2D_k7\" for i in range(len(numPc))]\n",
    "    file_names =['rawfilter_TRUE']+['minerva_first' + str(numPc[i]) + 'filter_TRUE' for i in range(1,len(numPc))]\n",
    "    select_columns_bool = True\n",
    "    select_labels = numPc#[\"Raw\"] + [\"Refactor\" + str(i) for i in range(1,len(numPc))] \n",
    "    metric_word = \"auc_all\"\n",
    "    chosen_classifier = \"Random Forest\"\n",
    "    title = 'AUC for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "    pair_test_all = False\n",
    "    limit_spec =(0.4,0.83)\n",
    "    not_rotate=True\n",
    "    \n",
    "#[0,1,2,3,10,20,40,60,80,100,140,150,200,220,240,260,300]#[0,1,2,3,10,20,30,40,50, 60, 70, 80 ,10]#\n",
    "lin_model = \"reg\"\n",
    "if not trans_vec:\n",
    "    trans = [\"clr_scale\" for i in range(len(file_names))]\n",
    "data_type = \"kmer\"\n",
    " #[0,0,0,0,1,1]#\n",
    "#[0,1,2,3,4,5,6,7,8,9,10]#[0,0,0,0,5,5]#[0,1,2,3,4,5,6,7,8,9,10]##[20,30,40,50,60,70,80,90,100,110,120,130,150,200]#[0,0,0,0,3,1,2]#[0,1,2,3,4,5,6,7,8,9,10]###,20,30,40,50,100,120,140] #[0,0,0,0,10,10,1] # [0\n",
    "#[key_folder for i in range(len(numPc))]\n",
    "#folder_names = [key_folder for i in range(len(numPc))]\n",
    "#folder_names = ['AGP_max_k6_subsample_' + str(i) + '_seed_1' for i in [20,40,60,80]]\n",
    "#['CRC_k6' for i in range(len(numPc))]#\n",
    "# [\"AGP_max_k5\",\"AGP_max_k6\",\"AGP_max_k7\"]#,\"AGP_max_k8\"]#['AGP_max_k7' for i in range(len(numPc))]\n",
    "#file_names = ['rawfilter_TRUE','smartsva_first2filter_TRUE','minerva_first2filter_TRUE']   #['smartsva_first10' + str(numPc[i]) + 'filter_TRUE' for i in range(len(numPc))]\n",
    "\n",
    "#file_names = ['rawfilter_TRUE']+['mine3rva_first' + str(numPc[i]) + 'filter_TRUE' for i in range(1,len(numPc))] \n",
    "#+['smartsva_first' + str(numPc[i]) + 'filter_TRUE' for i in range(1,len(numPc))]\n",
    "\n",
    "#file_names =['rawfilter_TRUE']+['minerva_plus_first' + str(numPc[i]) + 'filter_TRUE' for i in range(1,4)] + ['minerva_first' + str(numPc[i]) + 'filter_TRUE' for i in range(4,7)] \n",
    "#file_names =['rawfilter_TRUE']+['smartsva_first' + str(numPc[i]) + 'filter_TRUE' for i in range(1,len(numPc))] \n",
    "#file_names =['rawfilter_TRUE' for i in range(0,len(numPc))] \n",
    "\n",
    "#file_names =['rawfilter_TRUE']+['smartsva_first' + str(numPc[i]) + 'filter_TRUE' for i in range(1,len(numPc))]\n",
    "#file_names = ['rawfilter_TRUE']+['smartsva_first' + str(numPc[i]) + 'filter_TRUE' for i in range(1,len(numPc))]\n",
    "# #\n",
    "\n",
    "# file_names = ['rawfilter_TRUE','bmcfilter_TRUE','ComBatfilter_TRUE','limmafilter_TRUE',\n",
    "#              'smartsva_first7filter_TRUE','minerva_first6filter_TRUE']   #['smartsva_first10' + str(numPc[i]) + 'filter_TRUE' for i in range(len(numPc))]\n",
    "#'bmcfilter_TRUE','limmafilter_TRUE', ''refactor_first2filter_TRUE',\n",
    "#file_names = ['rawfilter_TRUE','ComBatfilter_TRUE','bmcfilter_TRUE','limmafilter_TRUE', 'smartsva_first6filter_TRUE','refactor_first7filter_TRUE','minerva_first7filter_TRUE']   #['smartsva_first10' + str(numPc[i]) + 'filter_TRUE' for i in range(len(numPc))]\n",
    "#file_names = ['rawfilter_TRUE']+ ['smartsva_first' + str(numPc[i]) + 'filter_TRUE' for i in range(1,len(numPc))]\n",
    "#file_names = ['rawfilter_TRUE']+ ['refactor_first' + str(numPc[i]) + 'filter_TRUE' for i in range(1,len(numPc))]\n",
    "\n",
    "file_names = [file_names[f] + \"_trans_\" + trans[f] for f in range(len(file_names))]\n",
    "nice_names = [\"7\" + '-mer' for i in range(len(numPc))]\n",
    "\n",
    "# file_names =[ 'kmer_BatchCorrected_antibiotic_classification_auc',\n",
    "#              'kmer_BatchCorrected_antibiotic_classification_auc',\n",
    "#              'kmer_BatchCorrected_antibiotic_classification_auc',\n",
    "#             'kmer_BatchCorrected_antibiotic_classification_auc']\n",
    "#folder_names = ['AGP_Hfilter_k5/robust_k','AGP_Hfilter_k6/robust_k','AGP_Hfilter_k7/robust_k','AGP_Hfilter_k8/robust_k']\n",
    "\n",
    "#folder_names = ['AGP_otumatch_otu','AGP_otumatch_k7','AGP_otumatch_k7'] #,'AGP_otumatch_k7']#['AGP_healthymax_k6', 'AGP_healthymax_k7']\n",
    "#['AGP_otumatch_otu','AGP_otumatch_k7','AGP_otumatch_k7']\n",
    "#['AGP_healthymax_k6', 'AGP_healthymax_k7']\n",
    "#nice_names = [\"5-mer\",\"6-mer\",\"7-mer\",\"8-mer\"] #,\"KMER\"]#, 'KMER old batch correct','KMER MINERVA']\n",
    "\n",
    "if phen_type == \"cont\":\n",
    "    \n",
    "    metric_word = 'pearson' # 'auc_all'#'pearson' # 'auc_all'#''auc_all' # 'pearson' # \n",
    "    classifier_name = 'bmi_prediction' #'bin_antibiotic_last_year'### #'bin_omnivore_diet'#'' 'bin_antibiotic_last_year'# #'Naive Bayes' #'\n",
    "    classifier = 'Regression'# \"Random Forest\"##\"Random Forest\"#'Regression'#\"Random Forest\"\n",
    "    classifier_ofc = \"Lin\"\n",
    "    title = 'Pearson correlation of ' + phen_pretty# 'AUC for prediction of antibiotic history'#'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "    special_name = phen[0] #\"Antibiotic history class prediction\"#\"Antibiotic history class prediction\"#\"BMI prediction\" #\"Antibiotic history class prediction\"#\"BMI prediction\"# \"Antibody prediction\"# \n",
    "else:\n",
    "    #'pearson' # 'auc_all'#''auc_all' # 'pearson' # \n",
    "    classifier_name = 'bin_antibiotic_last_year'### #'bin_omnivore_diet'#'' 'bin_antibiotic_last_year'# #'Naive Bayes' #'\n",
    "    classifier_ofc = \"Mixed\"\n",
    "    classifier = [chosen_classifier for f in file_names]#\"Naive Bayes\"#\"\"Naive Bayes\"#Random Forest\"#Random Forest\"#\"#'Regression'#\"Random Forest\"\n",
    "\n",
    "    #title = 'AUC for prediction of ' + phen_pretty #'AUC for prediction of antibiotic history'#'Pearson correlation of predicted body mass index (BMI)'#'AUC for prediction of antibiotic history'#' #AUC for prediction of antibiotic history' #\n",
    "    special_name = phen[0] #\"Antibiotic history class prediction\"#\"BMI prediction\" #\"Antibiotic history class prediction\"#\"BMI prediction\"# \"Antibody prediction\"# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['clr_scale', 'clr_scale', 'clr_scale', 'clr_scale', 'clr_scale']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AGP_max_k6', 'AGP_max_k6', 'AGP_max_k6', 'AGP_max_k6', 'AGP_max_k6']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rawfilter_TRUE_trans_clr_scale',\n",
       " 'bmcfilter_TRUE_trans_clr_scale',\n",
       " 'ComBatfilter_TRUE_trans_clr_scale',\n",
       " 'limmafilter_TRUE_trans_clr_scale',\n",
       " 'minerva_first2filter_TRUE_trans_clr_scale']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metric = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bmi_corrected',\n",
       " 'bmi_corrected',\n",
       " 'bmi_corrected',\n",
       " 'bmi_corrected',\n",
       " 'bmi_corrected']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/leahbriscoe/Documents/MicroBatch/microbatch_vc/data/AGP_max_k6/cont_pred/kmer_BatchCorrected_bmi_corrected_rawfilter_TRUE_trans_clr_scale_pearson_and_mse.pkl\n",
      "/Users/leahbriscoe/Documents/MicroBatch/microbatch_vc/data/AGP_max_k6/cont_pred/kmer_BatchCorrected_bmi_corrected_bmcfilter_TRUE_trans_clr_scale_pearson_and_mse.pkl\n",
      "/Users/leahbriscoe/Documents/MicroBatch/microbatch_vc/data/AGP_max_k6/cont_pred/kmer_BatchCorrected_bmi_corrected_ComBatfilter_TRUE_trans_clr_scale_pearson_and_mse.pkl\n",
      "/Users/leahbriscoe/Documents/MicroBatch/microbatch_vc/data/AGP_max_k6/cont_pred/kmer_BatchCorrected_bmi_corrected_limmafilter_TRUE_trans_clr_scale_pearson_and_mse.pkl\n",
      "/Users/leahbriscoe/Documents/MicroBatch/microbatch_vc/data/AGP_max_k6/cont_pred/kmer_BatchCorrected_bmi_corrected_minerva_first2filter_TRUE_trans_clr_scale_pearson_and_mse.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for f in range(len(file_names)):\n",
    "    \n",
    "    if metric_word == 'pearson':\n",
    "        if add_linmodel_type:\n",
    "            \n",
    "            filename_temp = data_folder + folder_names[f] +\"/\" + subfile + data_type + \"_BatchCorrected_\" + phen[f] + \"_\"+ file_names[f] + \"_lin_model_\" + lin_model +\"_pearson_and_mse.pkl\"\n",
    "        \n",
    "        else:\n",
    "            # \"_lin_model_\" + lin_model +\n",
    "            filename_temp = data_folder + folder_names[f] +\"/\" + subfile + data_type + \"_BatchCorrected_\" + phen[f] + \"_\"+ file_names[f] + \"_pearson_and_mse.pkl\"\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        filename_temp = data_folder + folder_names[f] + \"/\" +subfile + data_type + \"_BatchCorrected_\"+ phen[f] + \"_\" + file_names[f] + \"_classification_auc.pkl\"\n",
    "    print(filename_temp)\n",
    "    if os.path.isfile(filename_temp):\n",
    "        \n",
    "        data_temp = pickle.load( open( filename_temp ,\"rb\"))\n",
    "    \n",
    "        #methods_lists.append([k for k in data1.keys()]) \n",
    "        \n",
    "        if metric_word == \"auc_all\" or metric_word == \"accuracy\":\n",
    "            index = folder_names[f] + file_names[f]\n",
    "            #index = folder_names[f]\n",
    "            #index = nice_names[f] + \"_first_\" + str(numPc[f])\n",
    "            \n",
    "            df_metric[index] = pd.Series(data_temp[file_names[f]][classifier[f]][metric_word])\n",
    "            #nice_names[f] + \"_first_\" + str(numPc[f])\n",
    "        else:\n",
    "            #index = folder_names[f] + file_names[f]\n",
    "            index = file_names[f]\n",
    "            df_metric[index] = pd.Series(data_temp[metric_word])\n",
    "    else:\n",
    "        print(\"not file\")\n",
    "        print(file_names[f])\n",
    "        df_metric[nice_names[f] + file_names[f]] = 0\n",
    "        df_metric[nice_names[f] + file_names[f]] = 0\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metric.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.016237865243128674\n",
      "0.003922657641968592\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "delta = np.array(df_metric.iloc[:,4]-df_metric.iloc[:,0])\n",
    "print(np.mean(delta))\n",
    "print(scipy.stats.sem(delta))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rawfilter_TRUE_trans_clr_scale</th>\n",
       "      <th>bmcfilter_TRUE_trans_clr_scale</th>\n",
       "      <th>ComBatfilter_TRUE_trans_clr_scale</th>\n",
       "      <th>limmafilter_TRUE_trans_clr_scale</th>\n",
       "      <th>minerva_first2filter_TRUE_trans_clr_scale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.230212</td>\n",
       "      <td>0.229652</td>\n",
       "      <td>0.226903</td>\n",
       "      <td>0.229653</td>\n",
       "      <td>0.220322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.204323</td>\n",
       "      <td>0.205752</td>\n",
       "      <td>0.204912</td>\n",
       "      <td>0.205755</td>\n",
       "      <td>0.238865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.214889</td>\n",
       "      <td>0.214270</td>\n",
       "      <td>0.214536</td>\n",
       "      <td>0.214271</td>\n",
       "      <td>0.246922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.209751</td>\n",
       "      <td>0.209816</td>\n",
       "      <td>0.209131</td>\n",
       "      <td>0.209810</td>\n",
       "      <td>0.281483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.220855</td>\n",
       "      <td>0.218977</td>\n",
       "      <td>0.221370</td>\n",
       "      <td>0.218978</td>\n",
       "      <td>0.257774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.198615</td>\n",
       "      <td>0.197869</td>\n",
       "      <td>0.199378</td>\n",
       "      <td>0.197864</td>\n",
       "      <td>0.233297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.199193</td>\n",
       "      <td>0.198772</td>\n",
       "      <td>0.198137</td>\n",
       "      <td>0.198765</td>\n",
       "      <td>0.236404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.229219</td>\n",
       "      <td>0.229199</td>\n",
       "      <td>0.230114</td>\n",
       "      <td>0.229198</td>\n",
       "      <td>0.217803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.210252</td>\n",
       "      <td>0.211290</td>\n",
       "      <td>0.211244</td>\n",
       "      <td>0.211293</td>\n",
       "      <td>0.238313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.230503</td>\n",
       "      <td>0.230176</td>\n",
       "      <td>0.227861</td>\n",
       "      <td>0.230176</td>\n",
       "      <td>0.229279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.233852</td>\n",
       "      <td>0.233502</td>\n",
       "      <td>0.234346</td>\n",
       "      <td>0.233497</td>\n",
       "      <td>0.242391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.232886</td>\n",
       "      <td>0.232150</td>\n",
       "      <td>0.230228</td>\n",
       "      <td>0.232151</td>\n",
       "      <td>0.207226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.212896</td>\n",
       "      <td>0.214041</td>\n",
       "      <td>0.214472</td>\n",
       "      <td>0.214040</td>\n",
       "      <td>0.248478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.209891</td>\n",
       "      <td>0.210419</td>\n",
       "      <td>0.212233</td>\n",
       "      <td>0.210415</td>\n",
       "      <td>0.263188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.228204</td>\n",
       "      <td>0.228172</td>\n",
       "      <td>0.229881</td>\n",
       "      <td>0.228174</td>\n",
       "      <td>0.232294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.194517</td>\n",
       "      <td>0.193782</td>\n",
       "      <td>0.194579</td>\n",
       "      <td>0.193785</td>\n",
       "      <td>0.238303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.231930</td>\n",
       "      <td>0.230838</td>\n",
       "      <td>0.234118</td>\n",
       "      <td>0.230842</td>\n",
       "      <td>0.208581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.216358</td>\n",
       "      <td>0.217389</td>\n",
       "      <td>0.216905</td>\n",
       "      <td>0.217386</td>\n",
       "      <td>0.233318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.208370</td>\n",
       "      <td>0.208643</td>\n",
       "      <td>0.208556</td>\n",
       "      <td>0.208642</td>\n",
       "      <td>0.235655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.213100</td>\n",
       "      <td>0.212550</td>\n",
       "      <td>0.213944</td>\n",
       "      <td>0.212555</td>\n",
       "      <td>0.219261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.163759</td>\n",
       "      <td>0.161565</td>\n",
       "      <td>0.161405</td>\n",
       "      <td>0.161572</td>\n",
       "      <td>0.200085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.244794</td>\n",
       "      <td>0.242332</td>\n",
       "      <td>0.241742</td>\n",
       "      <td>0.242325</td>\n",
       "      <td>0.203907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.184990</td>\n",
       "      <td>0.183108</td>\n",
       "      <td>0.184540</td>\n",
       "      <td>0.183108</td>\n",
       "      <td>0.230152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.244690</td>\n",
       "      <td>0.240750</td>\n",
       "      <td>0.239996</td>\n",
       "      <td>0.240756</td>\n",
       "      <td>0.257501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.201723</td>\n",
       "      <td>0.200623</td>\n",
       "      <td>0.199565</td>\n",
       "      <td>0.200627</td>\n",
       "      <td>0.262654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.243247</td>\n",
       "      <td>0.241994</td>\n",
       "      <td>0.241251</td>\n",
       "      <td>0.241995</td>\n",
       "      <td>0.265360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.236047</td>\n",
       "      <td>0.235837</td>\n",
       "      <td>0.236378</td>\n",
       "      <td>0.235841</td>\n",
       "      <td>0.229575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.202225</td>\n",
       "      <td>0.201454</td>\n",
       "      <td>0.200158</td>\n",
       "      <td>0.201450</td>\n",
       "      <td>0.195777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.231825</td>\n",
       "      <td>0.231065</td>\n",
       "      <td>0.231039</td>\n",
       "      <td>0.231065</td>\n",
       "      <td>0.202496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.222452</td>\n",
       "      <td>0.223396</td>\n",
       "      <td>0.222879</td>\n",
       "      <td>0.223397</td>\n",
       "      <td>0.234418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.221833</td>\n",
       "      <td>0.220852</td>\n",
       "      <td>0.219913</td>\n",
       "      <td>0.220843</td>\n",
       "      <td>0.225507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.216576</td>\n",
       "      <td>0.215292</td>\n",
       "      <td>0.214733</td>\n",
       "      <td>0.215293</td>\n",
       "      <td>0.246413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.230463</td>\n",
       "      <td>0.229020</td>\n",
       "      <td>0.227016</td>\n",
       "      <td>0.229024</td>\n",
       "      <td>0.231951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.218770</td>\n",
       "      <td>0.218364</td>\n",
       "      <td>0.216261</td>\n",
       "      <td>0.218370</td>\n",
       "      <td>0.224332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.199268</td>\n",
       "      <td>0.199101</td>\n",
       "      <td>0.197630</td>\n",
       "      <td>0.199106</td>\n",
       "      <td>0.241426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.202345</td>\n",
       "      <td>0.201607</td>\n",
       "      <td>0.203296</td>\n",
       "      <td>0.201612</td>\n",
       "      <td>0.239578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.193223</td>\n",
       "      <td>0.192917</td>\n",
       "      <td>0.191000</td>\n",
       "      <td>0.192920</td>\n",
       "      <td>0.211568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.234981</td>\n",
       "      <td>0.234964</td>\n",
       "      <td>0.234433</td>\n",
       "      <td>0.234974</td>\n",
       "      <td>0.211614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.218070</td>\n",
       "      <td>0.218861</td>\n",
       "      <td>0.216058</td>\n",
       "      <td>0.218863</td>\n",
       "      <td>0.248964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.227356</td>\n",
       "      <td>0.226909</td>\n",
       "      <td>0.228326</td>\n",
       "      <td>0.226907</td>\n",
       "      <td>0.230703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.224817</td>\n",
       "      <td>0.225060</td>\n",
       "      <td>0.223261</td>\n",
       "      <td>0.225061</td>\n",
       "      <td>0.244822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.203714</td>\n",
       "      <td>0.203559</td>\n",
       "      <td>0.205129</td>\n",
       "      <td>0.203561</td>\n",
       "      <td>0.216736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.205663</td>\n",
       "      <td>0.203981</td>\n",
       "      <td>0.202975</td>\n",
       "      <td>0.203980</td>\n",
       "      <td>0.229695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.234116</td>\n",
       "      <td>0.235239</td>\n",
       "      <td>0.232580</td>\n",
       "      <td>0.235241</td>\n",
       "      <td>0.243986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.200760</td>\n",
       "      <td>0.201578</td>\n",
       "      <td>0.198689</td>\n",
       "      <td>0.201571</td>\n",
       "      <td>0.209632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.226686</td>\n",
       "      <td>0.225775</td>\n",
       "      <td>0.226089</td>\n",
       "      <td>0.225777</td>\n",
       "      <td>0.179527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.231232</td>\n",
       "      <td>0.230266</td>\n",
       "      <td>0.228872</td>\n",
       "      <td>0.230268</td>\n",
       "      <td>0.212867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.191440</td>\n",
       "      <td>0.190876</td>\n",
       "      <td>0.192057</td>\n",
       "      <td>0.190880</td>\n",
       "      <td>0.217308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.156298</td>\n",
       "      <td>0.157742</td>\n",
       "      <td>0.157447</td>\n",
       "      <td>0.157744</td>\n",
       "      <td>0.247230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.195699</td>\n",
       "      <td>0.194798</td>\n",
       "      <td>0.193524</td>\n",
       "      <td>0.194800</td>\n",
       "      <td>0.225839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rawfilter_TRUE_trans_clr_scale  bmcfilter_TRUE_trans_clr_scale  \\\n",
       "0                         0.230212                        0.229652   \n",
       "1                         0.204323                        0.205752   \n",
       "2                         0.214889                        0.214270   \n",
       "3                         0.209751                        0.209816   \n",
       "4                         0.220855                        0.218977   \n",
       "5                         0.198615                        0.197869   \n",
       "6                         0.199193                        0.198772   \n",
       "7                         0.229219                        0.229199   \n",
       "8                         0.210252                        0.211290   \n",
       "9                         0.230503                        0.230176   \n",
       "10                        0.233852                        0.233502   \n",
       "11                        0.232886                        0.232150   \n",
       "12                        0.212896                        0.214041   \n",
       "13                        0.209891                        0.210419   \n",
       "14                        0.228204                        0.228172   \n",
       "15                        0.194517                        0.193782   \n",
       "16                        0.231930                        0.230838   \n",
       "17                        0.216358                        0.217389   \n",
       "18                        0.208370                        0.208643   \n",
       "19                        0.213100                        0.212550   \n",
       "20                        0.163759                        0.161565   \n",
       "21                        0.244794                        0.242332   \n",
       "22                        0.184990                        0.183108   \n",
       "23                        0.244690                        0.240750   \n",
       "24                        0.201723                        0.200623   \n",
       "25                        0.243247                        0.241994   \n",
       "26                        0.236047                        0.235837   \n",
       "27                        0.202225                        0.201454   \n",
       "28                        0.231825                        0.231065   \n",
       "29                        0.222452                        0.223396   \n",
       "30                        0.221833                        0.220852   \n",
       "31                        0.216576                        0.215292   \n",
       "32                        0.230463                        0.229020   \n",
       "33                        0.218770                        0.218364   \n",
       "34                        0.199268                        0.199101   \n",
       "35                        0.202345                        0.201607   \n",
       "36                        0.193223                        0.192917   \n",
       "37                        0.234981                        0.234964   \n",
       "38                        0.218070                        0.218861   \n",
       "39                        0.227356                        0.226909   \n",
       "40                        0.224817                        0.225060   \n",
       "41                        0.203714                        0.203559   \n",
       "42                        0.205663                        0.203981   \n",
       "43                        0.234116                        0.235239   \n",
       "44                        0.200760                        0.201578   \n",
       "45                        0.226686                        0.225775   \n",
       "46                        0.231232                        0.230266   \n",
       "47                        0.191440                        0.190876   \n",
       "48                        0.156298                        0.157742   \n",
       "49                        0.195699                        0.194798   \n",
       "\n",
       "    ComBatfilter_TRUE_trans_clr_scale  limmafilter_TRUE_trans_clr_scale  \\\n",
       "0                            0.226903                          0.229653   \n",
       "1                            0.204912                          0.205755   \n",
       "2                            0.214536                          0.214271   \n",
       "3                            0.209131                          0.209810   \n",
       "4                            0.221370                          0.218978   \n",
       "5                            0.199378                          0.197864   \n",
       "6                            0.198137                          0.198765   \n",
       "7                            0.230114                          0.229198   \n",
       "8                            0.211244                          0.211293   \n",
       "9                            0.227861                          0.230176   \n",
       "10                           0.234346                          0.233497   \n",
       "11                           0.230228                          0.232151   \n",
       "12                           0.214472                          0.214040   \n",
       "13                           0.212233                          0.210415   \n",
       "14                           0.229881                          0.228174   \n",
       "15                           0.194579                          0.193785   \n",
       "16                           0.234118                          0.230842   \n",
       "17                           0.216905                          0.217386   \n",
       "18                           0.208556                          0.208642   \n",
       "19                           0.213944                          0.212555   \n",
       "20                           0.161405                          0.161572   \n",
       "21                           0.241742                          0.242325   \n",
       "22                           0.184540                          0.183108   \n",
       "23                           0.239996                          0.240756   \n",
       "24                           0.199565                          0.200627   \n",
       "25                           0.241251                          0.241995   \n",
       "26                           0.236378                          0.235841   \n",
       "27                           0.200158                          0.201450   \n",
       "28                           0.231039                          0.231065   \n",
       "29                           0.222879                          0.223397   \n",
       "30                           0.219913                          0.220843   \n",
       "31                           0.214733                          0.215293   \n",
       "32                           0.227016                          0.229024   \n",
       "33                           0.216261                          0.218370   \n",
       "34                           0.197630                          0.199106   \n",
       "35                           0.203296                          0.201612   \n",
       "36                           0.191000                          0.192920   \n",
       "37                           0.234433                          0.234974   \n",
       "38                           0.216058                          0.218863   \n",
       "39                           0.228326                          0.226907   \n",
       "40                           0.223261                          0.225061   \n",
       "41                           0.205129                          0.203561   \n",
       "42                           0.202975                          0.203980   \n",
       "43                           0.232580                          0.235241   \n",
       "44                           0.198689                          0.201571   \n",
       "45                           0.226089                          0.225777   \n",
       "46                           0.228872                          0.230268   \n",
       "47                           0.192057                          0.190880   \n",
       "48                           0.157447                          0.157744   \n",
       "49                           0.193524                          0.194800   \n",
       "\n",
       "    minerva_first2filter_TRUE_trans_clr_scale  \n",
       "0                                    0.220322  \n",
       "1                                    0.238865  \n",
       "2                                    0.246922  \n",
       "3                                    0.281483  \n",
       "4                                    0.257774  \n",
       "5                                    0.233297  \n",
       "6                                    0.236404  \n",
       "7                                    0.217803  \n",
       "8                                    0.238313  \n",
       "9                                    0.229279  \n",
       "10                                   0.242391  \n",
       "11                                   0.207226  \n",
       "12                                   0.248478  \n",
       "13                                   0.263188  \n",
       "14                                   0.232294  \n",
       "15                                   0.238303  \n",
       "16                                   0.208581  \n",
       "17                                   0.233318  \n",
       "18                                   0.235655  \n",
       "19                                   0.219261  \n",
       "20                                   0.200085  \n",
       "21                                   0.203907  \n",
       "22                                   0.230152  \n",
       "23                                   0.257501  \n",
       "24                                   0.262654  \n",
       "25                                   0.265360  \n",
       "26                                   0.229575  \n",
       "27                                   0.195777  \n",
       "28                                   0.202496  \n",
       "29                                   0.234418  \n",
       "30                                   0.225507  \n",
       "31                                   0.246413  \n",
       "32                                   0.231951  \n",
       "33                                   0.224332  \n",
       "34                                   0.241426  \n",
       "35                                   0.239578  \n",
       "36                                   0.211568  \n",
       "37                                   0.211614  \n",
       "38                                   0.248964  \n",
       "39                                   0.230703  \n",
       "40                                   0.244822  \n",
       "41                                   0.216736  \n",
       "42                                   0.229695  \n",
       "43                                   0.243986  \n",
       "44                                   0.209632  \n",
       "45                                   0.179527  \n",
       "46                                   0.212867  \n",
       "47                                   0.217308  \n",
       "48                                   0.247230  \n",
       "49                                   0.225839  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metric\n",
    "#df_metric.sort_values('OTUraw')\n",
    "#In this example, there are NO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rawfilter_TRUE_trans_clr_scale',\n",
       " 'bmcfilter_TRUE_trans_clr_scale',\n",
       " 'ComBatfilter_TRUE_trans_clr_scale',\n",
       " 'limmafilter_TRUE_trans_clr_scale',\n",
       " 'minerva_first2filter_TRUE_trans_clr_scale']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_columns = df_metric.columns #[ i + 'clr_pca_regress_out_no_scale_first10' for i in nice_names ] \n",
    "#select_labels = [\"raw\",\"ComBat\",\"BMC\",\"limma\",\"SmartSVA\",\"Refactor\",\"MINERVA\"]\n",
    "#select_labels = numPc\n",
    "#select_labels = [\"raw\",\"MINERVA\",\"Refactor\",\"SmartSVA\"]\n",
    "\n",
    "\n",
    "# ['Refactor CLR 100 SVs','Refactor CLR 220 SVs','MINERVA 100 SVs','MINERVA 220 SVs', \n",
    "#                  \"Refactor 120 SVs\", \"SmartSVA CLR 220 SVs\",\"SmartSVA 120 SVs\"]\n",
    "\n",
    "# select_labels = [\"MINERVA no std 10 SVs\", \"MINERVA std 10 SVs\",\"SmartSVA 10 SVs\", \n",
    "#                  \"MINERVA no std 5 SVs\", \"MINERVA std 5 SVs\",\"SmartSVA 5 SVs\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#[ i + ' MINERVA' for i in nice_names ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ['6-mers norm', '6-mers no_scale_clr','6-mers scale_clr','7-mers norm','7-mers no_scale_clr','7-mers scale_clr']\n",
    "# ['6-mers Raw', '6-mers MINVERVA','6-mers MINERVA-scale', '7-mers Raw','7-mers MINVERVA','7-mers MINVERVA-scale']\n",
    "# Make boxplot for one group only\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# select_columns = ['7-merclr_pca_regress_out_no_scale_first10filter_FALSE',\n",
    "#        '7-merclr_pca_regress_out_scale_first10filter_FALSE',\n",
    "#        '7-mersmartsva_first10filter_FALSE',\n",
    "#        '7-merclr_pca_regress_out_no_scale_first5filter_FALSE',\n",
    "#        '7-merclr_pca_regress_out_scale_first5filter_FALSE',\n",
    "#        '7-mersmartsva_first5filter_FALSE']\n",
    "\n",
    "# select_labels = [\"KMER MINERVA \"]\n",
    "\n",
    "# select_columns = ['OTUraw','OTUbmc','OTUComBat','OTUlimma',\n",
    "#                                  'KMERraw','KMERbmc','KMERComBat','KMERlimma',\n",
    "#                   \"KMERsmartsva_first10\",\"KMERrefactor_first10\",\n",
    "#                  \"KMERno_scale_clr\"]\n",
    "\n",
    "# select_columns = ['OTUraw','OTUbmc','OTUComBat','OTUlimma','KMERraw',\n",
    "#                   'KMERbmc','KMERComBat','KMERlimma',\"KMERsmartsva_first10\",\n",
    "#                   \"KMERrefactor_first10\", \"KMERclr_pca_regress_out_no_scale_first10\"]\n",
    "\n",
    "# select_columns = ['OTUraw','OTUbmc','OTUComBat','OTUlimma',\n",
    "#                                  'KMERraw','KMERbmc','KMERComBat','KMERlimma',\n",
    "#                   \"KMERsmartsva_first10\",\"KMERrefactor_first10\",\n",
    "#                  \"KMERno_scale_clr\"] #clr_pca_regress_out_no_scale_first10\n",
    "\n",
    "# ['OTUraw','OTUbmc','OTUComBat','OTUlimma',\n",
    "#                                  'OTUclr_pca_regress_out_no_scale',\"KMERnorm\",\"KMERno_scale_clr\"]\n",
    "\n",
    "# select_labels = ['OTU raw','OTU BMC','OTU ComBat','OTU limma',\n",
    "#                                      \"K-mer raw\",\"K-mer BMC\", \"K-mer ComBat\",\n",
    "#                 \"K-mer limma\",\"K-mer smartsva\",\"K-mer refactor\",\"K-mer MINERVA\"]\n",
    "#['OTU raw','OTU BMC','OTU ComBat','OTU limma',\"OTU MINERVA\",\"K-mer raw\", \"K-mer MINERVA\"]\n",
    "\n",
    "\n",
    "# ['OTU raw','OTU BMC','OTU ComBat','OTU limma',\n",
    "#                                      \"K-mer raw\",\"K-mer ComBat\",\"K-mer smartsva*\",\n",
    "#                                     \"K-mer MINERVA\"]\n",
    "sns.set_style(\"whitegrid\")\n",
    "if select_columns_bool:\n",
    "    \n",
    "    #plot_color[0:4] + [plot_color[7]] + [plot_color[4]] + [plot_color[7]\n",
    "    if not_rotate:\n",
    "        \n",
    "        current_palette = sns.color_palette()\n",
    "        #sns.palplot(current_palette)\n",
    "        #palette = sns.cubehelix_palette(df_metric.shape[1])\n",
    "        palette = sns.color_palette(\"Blues\", df_metric.shape[1])\n",
    "        plot_color = palette.as_hex()\n",
    "        \n",
    "        \n",
    "        \n",
    "        g=sns.boxplot( data = df_metric[select_columns],palette=plot_color)\n",
    "        g.set_xticklabels(labels = select_labels) #df_metric.columns\n",
    "    else:\n",
    "        \n",
    "        \n",
    "        current_palette = sns.color_palette()\n",
    "        #sns.palplot(current_palette)\n",
    "        #palette = sns.cubehelix_palette(df_metric.shape[1])\n",
    "        if not alternate_color:\n",
    "            #palette = sns.color_palette(\"Reds\", df_metric.shape[1]-1)\n",
    "            #plot_color = palette.as_hex()[::-1] + [\"#0093FF\"]#[\"#01d3e8\"]\n",
    "            \n",
    "            #palette = sns.color_palette(\"Reds\", 2)\n",
    "            #reds_color = palette.as_hex()[1:2]\n",
    "            \n",
    "            #palette = sns.color_palette(\"Oranges\", df_metric.shape[1]-2)\n",
    "            #oranges_color = palette.as_hex()\n",
    "            \n",
    "            #plot_color = reds_color + oranges_color +[\"#0093FF\"]\n",
    "            \n",
    "            \n",
    "            plot_color =['#e32f27','#FF9300','#FFE800','#fdd0a2',\"#0093FF\"]\n",
    "        else:\n",
    "            palette1 = sns.color_palette(\"Reds\", 2) [::-1] \n",
    "            palette2 = sns.color_palette(\"Blues\", 2)\n",
    "            plot_color = palette1.as_hex() + palette2.as_hex()\n",
    "            \n",
    "        g=sns.boxplot( data = df_metric[select_columns],palette=plot_color)\n",
    "        g.set_xticklabels(rotation=90,labels = select_labels) #df_metric.columns\n",
    "else:\n",
    "    g=sns.boxplot( data = df_metric)\n",
    "    g.set_xticklabels(rotation=90,labels = df_metric.columns)\n",
    "g.set(ylim=limit_spec)\n",
    "\n",
    "g.set_title(title)\n",
    "\n",
    "asterisk = [\"ns\",\"*\",\"**\",\"***\",\"****\"]\n",
    "\n",
    "#g=sns.boxplot( data = df_metric[select_columns],palette=plot_color)\n",
    "  \n",
    "# box_pairs=[(df_metric.columns[0], df_metric.columns[1]),\n",
    "#                                       (df_metric.columns[0], df_metric.columns[2]),\n",
    "#                                       (df_metric.columns[0], df_metric.columns[3]),\n",
    "#                                       (df_metric.columns[0], df_metric.columns[4])]\n",
    "# for a,b in box_pairs:\n",
    "#     print(a,b)\n",
    "#     t_stat = scipy.stats.ttest_rel(df_metric[a],df_metric[b], axis=0, nan_policy='propagate')\n",
    "#     print(t_stat.pvalue)\n",
    "#     if t_stat.pvalue < 0.05:\n",
    "#         ax.text(x=1, y=1, s=asterisk[0], va='center') \n",
    "\n",
    "if not_rotate:\n",
    "    \n",
    "    ref_col = df_metric.iloc[:,0]\n",
    "    tick_vec = g.get_xticks()[1:]\n",
    "else:\n",
    "    ref_col = df_metric.iloc[:,4]\n",
    "    tick_vec = g.get_xticks()[:-1]\n",
    "\n",
    "vertical_offset = 0.05\n",
    "for xtick in tick_vec:\n",
    "    \n",
    "    compare_col = df_metric.iloc[:,xtick]\n",
    "    median = np.max(compare_col)\n",
    "    \n",
    "    \n",
    "    t_res = ttest_rel(ref_col, compare_col)\n",
    "    p = t_res.pvalue\n",
    "\n",
    "    \n",
    "    if p > 5.00e-02 and p <= 1.00e+00:\n",
    "        asterisk_index = 0\n",
    "    elif 1.00e-02 < p  and p <= 5.00e-02:\n",
    "        asterisk_index = 1\n",
    "    elif 1.00e-03 < p and p <= 1.00e-02:\n",
    "        asterisk_index = 2\n",
    "    elif 1.00e-04 < p <= 1.00e-03:\n",
    "        asterisk_index = 3\n",
    "    elif p <= 1.00e-04:\n",
    "        asterisk_index = 4\n",
    "        \n",
    "        \n",
    "    \n",
    "    g.text(xtick,median + vertical_offset,asterisk[asterisk_index], \n",
    "            horizontalalignment='center',size='large',color='black',weight='semibold')\n",
    "    \n",
    "\n",
    "\n",
    "g.yaxis.grid(False)\n",
    "if metric_word== \"pearson\":\n",
    "    g.set(xlabel=\"Method\", ylabel = \"Pearson Correlation\")\n",
    "else:\n",
    "    g.set(xlabel=\"Method\", ylabel = \"AUC\")\n",
    "\n",
    "plt.savefig(plot_folder + chosen_classifier + data_type + \"_\" + trans[0] + '_boxplots_' + classifier_ofc + '_' + metric_word + \"_\" + special_name + '.pdf',bbox_inches='tight')\n",
    "plt.savefig(plot_folder + chosen_classifier + data_type + \"_\" + trans[0] +  '_boxplots_' + classifier_ofc + '_' + metric_word + \"_\" + special_name + '.png',bbox_inches='tight')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_rotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#e32f27', '#FF9300', '#FFE800', '#fdd0a2', '#0093FF']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rawfilter_TRUE_trans_clr_scale               0.214778\n",
       "bmcfilter_TRUE_trans_clr_scale               0.214323\n",
       "ComBatfilter_TRUE_trans_clr_scale            0.214022\n",
       "limmafilter_TRUE_trans_clr_scale             0.214324\n",
       "minerva_first2filter_TRUE_trans_clr_scale    0.231016\n",
       "dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metric.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value annotation legend:\n",
      "ns: 5.00e-02 < p <= 1.00e+00\n",
      "*: 1.00e-02 < p <= 5.00e-02\n",
      "**: 1.00e-03 < p <= 1.00e-02\n",
      "***: 1.00e-04 < p <= 1.00e-03\n",
      "****: p <= 1.00e-04\n",
      "\n",
      "rawfilter_TRUE_trans_clr_scale v.s. bmcfilter_TRUE_trans_clr_scale: t-test independent samples with Bonferroni correction, P_val=1.000e+00 stat=1.203e-01\n",
      "rawfilter_TRUE_trans_clr_scale v.s. ComBatfilter_TRUE_trans_clr_scale: t-test independent samples with Bonferroni correction, P_val=1.000e+00 stat=2.005e-01\n",
      "rawfilter_TRUE_trans_clr_scale v.s. limmafilter_TRUE_trans_clr_scale: t-test independent samples with Bonferroni correction, P_val=1.000e+00 stat=1.202e-01\n",
      "rawfilter_TRUE_trans_clr_scale v.s. minerva_first2filter_TRUE_trans_clr_scale: t-test independent samples with Bonferroni correction, P_val=2.577e-04 stat=-4.176e+00\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statannot import add_stat_annotation\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "\n",
    "x = \"Method\"\n",
    "y = \"AUC\"\n",
    "order = ['Sun', 'Thur', 'Fri', 'Sat']\n",
    "ax = sns.boxplot(data=df_metric,palette=plot_color)\n",
    "sns.set_context(\"paper\", font_scale=1.5) \n",
    "sns.set_style(\"whitegrid\")\n",
    "if pair_test_all:\n",
    "    if shortened:\n",
    "        if shortened_shortened:\n",
    "            add_stat_annotation(ax, data=df_metric,\n",
    "                        box_pairs=[(df_metric.columns[0], df_metric.columns[1]),\n",
    "                                  (df_metric.columns[0], df_metric.columns[2]),\n",
    "                                  (df_metric.columns[0], df_metric.columns[3]),\n",
    "                                  (df_metric.columns[2], df_metric.columns[3])],\n",
    "                        test='t-test_ind', text_format='star', loc='outside', verbose=2)\n",
    "        else:\n",
    "            if key == 'Gibbons':\n",
    "                add_stat_annotation(ax, data=df_metric,\n",
    "                            box_pairs=[(df_metric.columns[0], df_metric.columns[1]),\n",
    "                                      (df_metric.columns[0], df_metric.columns[2]),\n",
    "                                      (df_metric.columns[0], df_metric.columns[3]),\n",
    "                                      (df_metric.columns[0], df_metric.columns[4]),\n",
    "                                       (df_metric.columns[1], df_metric.columns[4])],\n",
    "                            test='t-test_ind', text_format='star', loc='outside', verbose=2)\n",
    "            else:\n",
    "                add_stat_annotation(ax, data=df_metric,\n",
    "                            box_pairs=[(df_metric.columns[0], df_metric.columns[1]),\n",
    "                                      (df_metric.columns[0], df_metric.columns[2]),\n",
    "                                      (df_metric.columns[0], df_metric.columns[3]),\n",
    "                                      (df_metric.columns[0], df_metric.columns[4])],\n",
    "                            test='t-test_ind', text_format='star', loc='outside', verbose=2)\n",
    "\n",
    "    else:\n",
    "        add_stat_annotation(ax, data=df_metric,\n",
    "                        box_pairs=[(df_metric.columns[0], df_metric.columns[1]),\n",
    "                                  (df_metric.columns[0], df_metric.columns[2]),\n",
    "                                  (df_metric.columns[0], df_metric.columns[3]),\n",
    "                                  (df_metric.columns[0], df_metric.columns[4]),\n",
    "                                  (df_metric.columns[0], df_metric.columns[5]),\n",
    "                                  (df_metric.columns[0], df_metric.columns[6])],\n",
    "                        test='t-test_ind', text_format='star', loc='outside', verbose=2)\n",
    "\n",
    "else:\n",
    "    add_stat_annotation(ax, data=df_metric,\n",
    "                    box_pairs=[(df_metric.columns[0], df_metric.columns[11])],\n",
    "                    test='t-test_paired', text_format='star', loc='outside', verbose=2)\n",
    "# , (df_metric.columns[0], df_metric.columns[5])\n",
    "if not_rotate:\n",
    "    ax.set_xticklabels(labels = select_labels)\n",
    "else:\n",
    "    ax.set_xticklabels(rotation=90,labels = select_labels)\n",
    "ax.set(ylim=limit_spec)\n",
    "ax.set_title(title)\n",
    "plt.savefig(plot_folder + chosen_classifier + data_type + \"_\" + trans[0] + '_boxplots_' + classifier_ofc + '_' + metric_word + \"_\" + special_name + '_2.pdf',bbox_inches='tight')\n",
    "#(df_metric.columns[0], df_metric.columns[2]),\n",
    "#                              (df_metric.columns[0], df_metric.columns[3]),\n",
    "#                             (df_metric.columns[0], df_metric.columns[4]),\n",
    "#                             (df_metric.columns[0], df_metric.columns[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
